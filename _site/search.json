[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Por una Ciencia Reproducible 2025",
    "section": "",
    "text": "Nuestros Blogs\n\n\n\n\n\n\ncomunidad\n\n\nparticipantes\n\n\nejemplos\n\n\ngalería\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 2 de mayo, 2025\n\n\nAdrian Canova Herrandiz, Andrés De la Rosa Portilla, Denisse Alejandra Diaz Romo, Guadalupe Méndez Dewar, Juan José Hernández Viveros, Mordecai , Nohemy Cardona Claros, Ulises Zarate, Vicky Delgadillo, Victoria Carolina\n\n\n\n\n\n\n\n\n\n\n\n\nOtra manera de Presentar\n\n\n\n\n\n\nmapas\n\n\nrevealjs\n\n\nextensiones\n\n\ndiapo portada\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 25 de abril, 2025\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nPizzas\n\n\n\n\n\n\nestadística\n\n\nreporte\n\n\nartículo\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 24 de abril, 2025\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\n¿Narrativas con datos?\n\n\n\n\n\n\ntipos de estudio\n\n\nexperimento\n\n\nmuestreo\n\n\nencuesta\n\n\ndivulgación\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 10 de abril, 2025\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nDatos abiertos\n\n\n\n\n\n\ndatos abiertos\n\n\nscraping\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 10 de abril, 2025\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nDar formato a mi documeto\n\n\n\n\n\n\ndiv\n\n\nfences\n\n\npestañas\n\n\ncajas\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 4 de abril, 2025\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\n¿Qué tipo de proyecto presenta mi blog?\n\n\n\n\n\n\ntipos de estudio\n\n\nexperimento\n\n\nmuestreo\n\n\nencuesta\n\n\ndivulgación\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 21 de marzo, 2025\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\n¿Qúe puedo incluir en mis documentos?\n\n\n\n\n\n\nmapas\n\n\ntablas\n\n\ngráficas\n\n\ngalería\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 28 de febrero, 2025\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nLos primeros pasos\n\n\n\n\n\n\ntaller\n\n\ninicio\n\n\nmarkdown\n\n\nrstudio\n\n\ngit\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 21 de febrero, 2025\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nUna Nueva Manera de Escribir\n\n\n\n\n\n\ntaller\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 14 de febrero, 2025\n\n\nMiguel Equihua\n\n\n\n\n\n\n\n\n\n\n\n\nBlog de Reproducibilidad Científica\n\n\n\n\n\n\n\n\n\n\n\nXalapa, Ver., 14 de febrero, 2025\n\n\nMiguel Equihua\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "posts/2025-04-24-paper-typst/index.html",
    "href": "posts/2025-04-24-paper-typst/index.html",
    "title": "Pizzas",
    "section": "",
    "text": "Para encontrar una mejor manera de hacer su pizza favorita, Marcelo se propuso reducir el tiempo que tarda en preparar la masa. Para hacerlo siguió el camino de la ciencia y diseñó un experimento para poner a prueba el efecto de la cantidad de azúcar y de leche en los tiempos de activación de la levadura. En concreto, probó cuatro recetas diferentes y midió cuántos segundos tardaba la misma cantidad de masa en llenar un recipiente hasta una marca que fijo como referencia. Aleatorizó el orden de las recetas y repitió cada tratamiento 4 veces.\n\n\nDescargar los datos en formato de texto simple o Utiliza este vínculo para otenerlo de Google Drive\n\n\nPuedes usar instrucciones parecidas a las que siguen para leer los datos en R, directamente desde un documento en la nube de Google Drive. Nota que en este ejemplo deberás cambiar datos por un nombre de tu preferencia. Yo elegí masa.\n\nlibrary(stringr)\nurl_datos &lt;- \"URL de los datos\"\ndat_datos_id &lt;- str_extract(url_datos, \"(?&lt;=d/)(.*)(?=/view)\")\n\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \nmasa &lt;- read.csv(sprintf(url_drive, dat_datos_id)) \n\n\n\n¿Diseño experimental?\n¿Arreglo de tratamientos?\n¿Modelo que corresponde a este experimento?\n¿Supuestos qe harás para apoyar tu análisis estadístico?\n¿Define tu criterio o nivel de significancia?\nRealiza una exploración de los datos, numérica y gráfica, comenta\nConstruye los modelos necesarios y selecciona el mínimo adecuado\nValora la calidad del modelo, incluyendo el análisis de los residuos\nResuelve que tratamientos difieren de los demás\nArgumenta tus conclusiones\n\n\n\n \nLa tarea consiste en que preparas un reporte con el formato de un artículo y que sea parte de tu blog. En este caso usarás la extensión academic-typst que está en la página de extensiones de Quarto. Para incorporar esta extensión a tu proyecto usa el siguiente comando en la pestaña de terminal.\n\nquarto use template kazuyanagimoto/quarto-academic-typst\n\nUna ves que lo hayas instalado aparecerá un nuevo directorio en la raíz de tu proyecto con el nombre _extensions y también un archivo que te servira de templete con el nombre template-full.qmd, otro con los datos de las referencias: references.bib y un directorio img. Muévelos todos por favor a posts, a un subdirectorio apropiado para que mantengas el orden de tu trabajo. Para que experimentes un poco sobre la flexibilidad de lo que estamos haciendo, agrega lo siguiente en la sección de formato del encabezado yaml del templete, arribita de academic-typst. Hay un directorio con fonts que te hará falta si quieres usar el templete tal y como está, aunque realmente no es indispensable. Los fonts los puedes descargar con el botón.\n Descarga los fonts en el zip \n \nformat:\n     html: default\n     docx: default\nLa idea es que experimentes con la preparación de un reporte técnico con Quarto. Ejercita también la inclusión de referencias bibliográficas. En el encabezado del reporte te sugiero cambiar el formato de la bibliografia para compatibilidad con typst, de chicago a APA. Para eso substituye la frase en bibliographystyle: a que diga “american-psychological-association”, en lugar de “chicago-author-date” que es lo que tiene el templete. Para agregar referencias y para buscarlas en internet resulta muy cómodá la opción de insertar referencias que ofrece RStudio en su modo visual (Figura 1). Otra herramienta para esto mismo es Zotero, que se puede usar para cosechar referencias de internet y vincularlas a Quarto e incluso para capturarlas manualmente. La sección de referencias puede personalizarse con un divo así:\n\n:::{#refs}\n## Referencias\n:::\n\n \n\n\n\nFigura 1\n\n\n\n\n\n\nPara averiguar un poco más sobre esto te invito a visitar este documento. Incluso podrías interesarte en preparar un libro completo ¡Quizás es algo que podrías querer hacer para producir el documento de tu tesis! Bueno, por lo pronto lo que sigue es que construyas tu reporte, siguiendo ideas de formateo que te sugiere el templete. La idea es algo así."
  },
  {
    "objectID": "posts/2025-04-24-paper-typst/index.html#preparación-de-la-masa",
    "href": "posts/2025-04-24-paper-typst/index.html#preparación-de-la-masa",
    "title": "Pizzas",
    "section": "",
    "text": "Para encontrar una mejor manera de hacer su pizza favorita, Marcelo se propuso reducir el tiempo que tarda en preparar la masa. Para hacerlo siguió el camino de la ciencia y diseñó un experimento para poner a prueba el efecto de la cantidad de azúcar y de leche en los tiempos de activación de la levadura. En concreto, probó cuatro recetas diferentes y midió cuántos segundos tardaba la misma cantidad de masa en llenar un recipiente hasta una marca que fijo como referencia. Aleatorizó el orden de las recetas y repitió cada tratamiento 4 veces.\n\n\nDescargar los datos en formato de texto simple o Utiliza este vínculo para otenerlo de Google Drive\n\n\nPuedes usar instrucciones parecidas a las que siguen para leer los datos en R, directamente desde un documento en la nube de Google Drive. Nota que en este ejemplo deberás cambiar datos por un nombre de tu preferencia. Yo elegí masa.\n\nlibrary(stringr)\nurl_datos &lt;- \"URL de los datos\"\ndat_datos_id &lt;- str_extract(url_datos, \"(?&lt;=d/)(.*)(?=/view)\")\n\nurl_drive &lt;- \"https://docs.google.com/uc?id=%s&export=download\" \nmasa &lt;- read.csv(sprintf(url_drive, dat_datos_id)) \n\n\n\n¿Diseño experimental?\n¿Arreglo de tratamientos?\n¿Modelo que corresponde a este experimento?\n¿Supuestos qe harás para apoyar tu análisis estadístico?\n¿Define tu criterio o nivel de significancia?\nRealiza una exploración de los datos, numérica y gráfica, comenta\nConstruye los modelos necesarios y selecciona el mínimo adecuado\nValora la calidad del modelo, incluyendo el análisis de los residuos\nResuelve que tratamientos difieren de los demás\nArgumenta tus conclusiones\n\n\n\n \nLa tarea consiste en que preparas un reporte con el formato de un artículo y que sea parte de tu blog. En este caso usarás la extensión academic-typst que está en la página de extensiones de Quarto. Para incorporar esta extensión a tu proyecto usa el siguiente comando en la pestaña de terminal.\n\nquarto use template kazuyanagimoto/quarto-academic-typst\n\nUna ves que lo hayas instalado aparecerá un nuevo directorio en la raíz de tu proyecto con el nombre _extensions y también un archivo que te servira de templete con el nombre template-full.qmd, otro con los datos de las referencias: references.bib y un directorio img. Muévelos todos por favor a posts, a un subdirectorio apropiado para que mantengas el orden de tu trabajo. Para que experimentes un poco sobre la flexibilidad de lo que estamos haciendo, agrega lo siguiente en la sección de formato del encabezado yaml del templete, arribita de academic-typst. Hay un directorio con fonts que te hará falta si quieres usar el templete tal y como está, aunque realmente no es indispensable. Los fonts los puedes descargar con el botón.\n Descarga los fonts en el zip \n \nformat:\n     html: default\n     docx: default\nLa idea es que experimentes con la preparación de un reporte técnico con Quarto. Ejercita también la inclusión de referencias bibliográficas. En el encabezado del reporte te sugiero cambiar el formato de la bibliografia para compatibilidad con typst, de chicago a APA. Para eso substituye la frase en bibliographystyle: a que diga “american-psychological-association”, en lugar de “chicago-author-date” que es lo que tiene el templete. Para agregar referencias y para buscarlas en internet resulta muy cómodá la opción de insertar referencias que ofrece RStudio en su modo visual (Figura 1). Otra herramienta para esto mismo es Zotero, que se puede usar para cosechar referencias de internet y vincularlas a Quarto e incluso para capturarlas manualmente. La sección de referencias puede personalizarse con un divo así:\n\n:::{#refs}\n## Referencias\n:::\n\n \n\n\n\nFigura 1\n\n\n\n\n\n\nPara averiguar un poco más sobre esto te invito a visitar este documento. Incluso podrías interesarte en preparar un libro completo ¡Quizás es algo que podrías querer hacer para producir el documento de tu tesis! Bueno, por lo pronto lo que sigue es que construyas tu reporte, siguiendo ideas de formateo que te sugiere el templete. La idea es algo así."
  },
  {
    "objectID": "posts/2025-03-21-tipo-de estudio/index.html",
    "href": "posts/2025-03-21-tipo-de estudio/index.html",
    "title": "¿Qué tipo de proyecto presenta mi blog?",
    "section": "",
    "text": "Los proyectos que suelen abordarse en una especialización científca o tecnológica abordan desafíos de identificación y medición de relaciones causales, estimación del estado de variables ambientales, demográficas, económicas, etc., representación gráfica de procesos, mecanismos o de la distribución geográfica de variables de interés. También puede interesar la construcción de formas de comunicación efectiva a actores relevantes pero no especializados en términos de preparación universitaria formal. Será tu desafío precisar la naturaleza del proyecto que será la base formal de tu Blog. Recuerda mantener una perspectiva de narrativa basada en datos, y de la importancia de la trazabilidad de la evidencia y de los procesos analíticos utilizados.\nPara ayudarte a poner tus intereses en perspectiva conviene hablar sobre como se caracterizan generalmente los tipos de estudio científicos y tecnológicos. Un primer asunto es considerar si se trata de estudios que se basaran en datos ya existentes (retrospectiva) o datos nuevos que se planea producir (prospectivo).\nOtro aspecto a considerar es si para los fines del trabajo se requiere una sóla medición en el tiempo (transversal) o si se requiere dar sguimiento a la evolución del fenómeno con mediciones repetidas varias veces a lo largo del tiempo (longitudinal).\nFinalmente es necesario resolver si los propósitos del estudio se requiere caracterizar una sóla población objetivo (descriptivo) o si interesa comparar y contrastar dos o más poblaciones (comparativo). Desde luego por población me refiero a la idea estadística que propone una definición abstracta de un conjunto de entidades observables, que se caracterizan con referencia precisa a un conjunto de atributos medibles o variables concretas.\nA partir de estos elementos es posible clasificar los tipos de estudios que se realizan. Desafortunadamente, las distintas disciplinas tienden a denominar cada combinación de atributos de maneras algo peculiares. No me ocuparé de eso, lo que interesa aquí es ayudarte a clarificar la naturaleza de tu proyecto. Usualmente un estudio observacional, y descriptivo y retrospectivo corresponde con la práctica de revisión de casos o de análisis de microdatos censales (es decir los cuestionarios individuales levantados en campo), esto es lo que explica INEGI que hace como procedimiento para obtenerlos. Desde luego, esto también se puede hacer con un propósito comparativo, los médicos y epidemiólogos lo llaman estudio de casos y controles, o perspectiva histórica tú, ¿cómo lo llamarías?. Finalmente, si el planteamiento es experimental y prospectivo, estás en el ámbito de un experimento controlado.\nPodemos decir, en resumen, que los estudios pueden concebirse por muy distintas razones, ningúna mejor que otra en general, cada una más bien sencible y adecuada a lo que la siruación de interés requiere:\nEn todos estos casos existe una gran oferta de métodos estadísticos de procesamiento de datos para evitar el efecto distractor de los factores y procesos de confusión que dificultan comprender la consistencia y relevancia de los hallazgos científicos y tecnológicos. Recientemente se ha avanzado mucho a este respecto con el uso de diagramas causales y el entendimiento de los patrones de correlación que cabría esperar en tus datos, suponiendo que la proposición causal que imaginas para explicarlas, sea razonablemente apegada al proceso que estas analizando. Estos diagramas son conocidos como DAG (Directed Acyclic Graphs) y encontraras una referencia interesante a ellos en (Pearl & Mackenzie, 2020).\nSi tu estudio es más de tipo retrospectivo es decir buscas analizar datos estadísticos o vas a realizr una encuesta, el libro en línea de (Zimmer, 2024) es una fuente iteresante. Si por el contrario, te inclinas por un trabajo del tipo de experimento controlado, te sugiero el libro de (Lawson, 2014). Finalmente, te sugiero consideres también el punto de vista que propone para repensar el uso de la estadística este otro autor (McElreath, 2020). Puede interesrte también ete artículo sobre los datos abiertos que ofrece Inegi y la bilioteca para R que han desarrollado. Este otro es un ejemplo detallado de acceso y procesamiento de microdatos. Algo semejante ofrece este artículo de Castro (2021) y está también el libro completo en línea d Escoto Castillo (2021), sobre como usar microdato para analizar el mercado de tabajo."
  },
  {
    "objectID": "posts/2025-03-21-tipo-de estudio/index.html#lecturas-sugeridas",
    "href": "posts/2025-03-21-tipo-de estudio/index.html#lecturas-sugeridas",
    "title": "¿Qué tipo de proyecto presenta mi blog?",
    "section": "Lecturas sugeridas",
    "text": "Lecturas sugeridas\n\nCastro, C. D. P. (2021). Usando R para jugar con los microdatos del INEGI. En tacosdedatos. https://bit.ly/3Fz35Vh\n\n\nEscoto Castillo, A. R. (2021). ¿Cómo empezar a estudiar el mercado de trabajo en México? (Una introducción al análisis estadístico con R aplicado a la Encuesta Nacional de Ocupación y Empleo). UNAM. https://bit.ly/3XRrxYa\n\n\nLawson, J. (2014). Design and Analysis of Experiments with R. CRC press. https://bit.ly/3DR0ipN\n\n\nMcElreath, R. (2020). Statistical Rethinking  A Bayesian Course with Examples in R and Stan. Chapman & Hall: CRC Press. https://xcelab.net/rm/\n\n\nPearl, J., & Mackenzie, D. (2020). El libro del porqué. Pasado y Presente. https://www.marcialpons.es/media/pdf/ellibrodelporquejudeapearl.pdf\n\n\nZimmer, J. P., Stephanie A. (2024). Exploring Complex Survey Data Analysis Using R. Chapman & Hall: CRC Press. https://tidy-survey-r.github.io/tidy-survey-book/"
  },
  {
    "objectID": "posts/2025-04-11-datos-abiertos/index.html",
    "href": "posts/2025-04-11-datos-abiertos/index.html",
    "title": "Datos abiertos",
    "section": "",
    "text": "La preparación, oferta y mantenimiento de datos abiertos es parte de los intereses en búsqueda de una ciencia abierta. En este sentido conviene considerar los principios de la iniciativa de Budapest, Hungría en torno a publicación abierta. Esta iniciativa fue publicada el 14 de febrero 2002. Especialmente importante resulta la recomendación de desarrollar capacidades de “self-archiving” siguiendo estándares de la iniciativa de repositorios abiertos. Aunque esta última propuesta ya nos está en desarrollo activo, fue el antecedente que dio origen al estándar ANSI/NISO Z39.99-2017 para el acceso bibliográfico. De aquí emerge tamién el protocolo de cosecha de metadatos OAI-PMH, cuyas especificaciones continúan vigentes, y tiene nuevos desarrollos o actualizaciones como el ANSI/NISO 2017 aunque no se trata necesariamente de un reemplazo. De la iniciativa de Budapest emerge una guía interesante en torno al establecimiento de repositorios institucionales (de publicaciones). En su propio manifiesto del 2023, REDALYC refrenda los valores enunciados en la iniciativa de Budapest.\nEn México se han tenido expresiones positivas en torno a esta iniciativa desde su aparición en 2002. Por ejemplo, del Senado de la República, la UNAM, UAEM, CONACYT y la UAM, entre otras. Si bien la iniciativa de Budapest se enfoca en la publicación abierta, resulta claro que no basta con tener acceso a la publicación como producto final de las investigaciones, se requiere compartir también los datos base de los estudios, como se explica en esta nota de Verhulst, Zahuranec & Young (2021), que retoma parte de la serie “Great Stories of Open Science” que se publica con el apoyo del Ministerio Francés de Educación Superior, Investigación e Innovación\nUn ejemplo del proceso de adopción de los principios FAIR se presenta en el reporte aparecido en 2018 de la experiencia europea: Turning FAIR into reality: final report and action plan from the European Commission expert group on FAIR data, Publications Office. En este mismo sentido y en la confluencia de esfuerzos que impulsan los valores de la ciencia abierta esta también SPARC, que es una organización Norteamericana con filiales en Europa, África y Japón, sin fines de lucro. Promueve el desarrollo de sistemas para la investigación y la educación que sean abiertos en forma predeterminada y equitativos por diseño. La experiencia europea de SPARC ha producido documentos útiles como referencia y fuente de inspiración:\nEsta misma organización ofrece orientación para la definición de metadatos por áreas del conocimiento, lo que resulta muy útil. La página ofrece colecciones de estándares existentes y ayudan así al interesado a conocer las diversas aproximaciones que se han ensayado.\nDe acuerdo con los criterios que emanan de los principio FAIR, los datos pueden estar en distintos niveles de acceso abierto. Así, se puede definir la escalera de estructuración y acceso. En el nivel más simple encontramos datos contenidos en documentos de texto, por ejemplo PDF. En el otro extremo, con plena accesibilidad digital, están los verdaderos datos abiertos que cumplen a plenitud con los criterio FAIR."
  },
  {
    "objectID": "posts/2025-04-11-datos-abiertos/index.html#ejemplos-de-soluciones-de-datos-abiertos",
    "href": "posts/2025-04-11-datos-abiertos/index.html#ejemplos-de-soluciones-de-datos-abiertos",
    "title": "Datos abiertos",
    "section": "Ejemplos de soluciones de datos abiertos",
    "text": "Ejemplos de soluciones de datos abiertos\n\nUniatmos\nEs la Unidad de Informática para las Ciencias Atmosféricas y Ambientales gestionada por el Instituto de de la Atmósfera y Cambio Climático de la UNAM.\n\n\n\n\n\nZenodo\nSe trata de un espacio construido y desarrollado por investigadores, para garantizar que todo el mundo pueda participar en la Ciencia Abierta. El proyecto OpenAIRE fue desarrollado por indicaciones la Comunidad Europea para apoyar su incipiente política de Datos Abiertos. Con esta plataforma se ofrece un repositorio general para la investigación financiada por la Comnidad Europea. El CERN, socio de OpenAIRE y pionero en código abierto, acceso abierto y datos abiertos, proporcionó esta capacidad para lograr que Zenodo estuviera en operación a partir de mayo de 2013. En apoyo de su programa de investigación, el CERN ha desarrollado herramientas para la gestión de Big Data y ha ampliado las capacidades de la biblioteca digital para Open Data. A través de Zenodo, estas herramientas de Big Science pueden así compartirse eficazmente.\n\n\n\n\n\n\nDatadryad\n\n\n\n\n\n\nEs una plataforma de publicación de datos abiertos y una comunidad comprometida con la disponibilidad abierta y la reutilización rutinaria de todos los datos de investigación.\n\n\n\n\n\n\n\n\nFigshare\n\n\n\n\n\n\nEs un repositorio en el que los usuarios pueden poner a disposición todos los resultados de sus investigaciones de forma que se puedan citar, compartir y descubrir."
  },
  {
    "objectID": "posts/2025-04-11-datos-abiertos/index.html#metadatos-y-ejemplos-de-datos-abiertos",
    "href": "posts/2025-04-11-datos-abiertos/index.html#metadatos-y-ejemplos-de-datos-abiertos",
    "title": "Datos abiertos",
    "section": "Metadatos y ejemplos de datos abiertos",
    "text": "Metadatos y ejemplos de datos abiertos\n\nUnión Europea: datos abiertos\n\n\nMetadatos ámbito biológico: Darwin Core\n\nDGRU-UNAM\nGBIF\nCONABIO\n\n\n\nMetadatos ámbito ciencias de la Tierra ISO-19115\nLa documentación de los metadatos cartográficos que utiliza Conabio sigue los estándares definidos en FGDC (1998) y FGDC (1999). De acuerdo con lo qe nos explicó el Ing. Fernández, el estándar de metadatos FGDC ha sido remplazado actualmente por el ISO-19115.\n\nInegi\nCONABIO\n\n\n\nOtros ejemplos con datos climáticos y ambientales en general\n\nOpen Geospatial Consortium standards.\nUse of international metadata standards to be interoperable. World Meteorological Organization Information System (WIS.) INSPIRE Knowledge base - Metadata.\nClimate Resilience Information Systems.\n\n\n\n\n\n\n\nDatos Abiertos: Recomendaciones para producirlos\n\n\n\n\n\n\nDatos abiertos para principiantes\nEl grupo Safe Software produjo este libro electrónico, que explica en forma sencilla asuntos importantes a tener en cuenta.\n\n\nMantenlo simple\nInicia con asuntos pequeños, simples y de solución rápida. No hay necesidad de correr a abrir todos los datos de inmediato. Hacer de acceso abierto un conjunto pequeño de datos o parte del big data es suficiente para empezar y ganar experiencia.\n\n\nInvolucrarse pronto y hacerlo frecuentemente\nHay que acercarse tan pronto como sea posible a los usuarios reales y potenciales. Hay que pensar en quienes podrían utilizar los datos para crear otros productos de información. Estos actores pueden ser ciudadanos, empresarios, desarrolladores o intermediarios.\n\n\nAtender los miedos y malos entendidos comunes\nEsto es especialmente importante si estas trabajando con o dentro de una institución grande como suelen ser las áreas gubernamentales. Cuando se trata de abrir los acervos de datos es de esperar que surjan muchas preguntas, dudas y temores. Es importante identificar los más importantes de ellos y enfrentarlos de inmediato."
  },
  {
    "objectID": "posts/2025-04-11-datos-abiertos/index.html#recursos-para-facilitar-el-compartir",
    "href": "posts/2025-04-11-datos-abiertos/index.html#recursos-para-facilitar-el-compartir",
    "title": "Datos abiertos",
    "section": "Recursos para facilitar el compartir",
    "text": "Recursos para facilitar el compartir\n\nCreative commons\nCopyleft\nThe MIT License\nDOI\n\n\nIndautor\nPuedes visitar en México el Instituto Nacional del Derecho de Autor para obtener más información."
  },
  {
    "objectID": "posts/2025-04-11-datos-abiertos/index.html#cómo-podemos-usar-datos-abiertos",
    "href": "posts/2025-04-11-datos-abiertos/index.html#cómo-podemos-usar-datos-abiertos",
    "title": "Datos abiertos",
    "section": "¿Cómo podemos usar datos abiertos?",
    "text": "¿Cómo podemos usar datos abiertos?\nAhora te propongo pasar a la práctica y explorar algunas cosas que te darán idea de como es que puedes aprovechar datos abiertos de tu interés. En el caso de México, como ya comenté, Inegi, Conabio y en general datos.gob.mx son referencias importantes de proveedores de datos de México. Te propongo ver algunos ejemplos de como puedes aprovechar estos datos. Desde luego, una forma de hacerlo es por la ruta de descargar lo que necesites y a partir de ahí hacer tu procesamiento de valor agregado para generar nuevos productos de información que se alinean con los fines de tu proyecto. Otra forma de hacerlo es recurriendo a canales de flujo de datos que muchas veces se pueden aprovechar mediante el uso de API (Interfaz de Programación de Aplicaciones). Las API son creadas, diseñadas y utilizadas para lograr una interacción ordenada y coherente entre aplicaciones, sin necesidad de saber más que las especificaciones que definen a la API y nada de la estructura interna del servicio que deseamos utilizar. Naturalmente Esto simplifica el desarrollo de nuevas aplicaciones. No es mi pretención cubrir ampliamente el tema, pero considero potencialmente interesante para ti saber algo de este tema, que te abre las puertas al acceso a muchas cosas en la World Wide Web actual. Te presentaré algunos ejemplos y espero me propongas ideas de como utilizar estas ideas en tu proyecto.\n\n\ndatos.gob.mx\nPara empezar, debes saber que estos datos están cubiertos por la licencia libre uso MX. Esta licencia busca promover el uso, reuso y redistribución de conjuntos de datos de acuerdo con una serie de criterios que se especificán aquí y que indica, entre otras cosas que puedes:\n\nHacer y distribuir copias del conjunto de datos y su contenido;\nDifundir y publicar el conjunto de datos y su contenido;\nAdaptar o reordenar el conjunto de datos y su contenido;\nExtraer total o parcialmente el contenido del conjunto de datos;\nExplotar comercialmente el conjunto de datos y su contenido, y;\nCrear conjuntos de datos derivados del conjunto de datos o su contenido.\n\n\n\n\nCatálogo de datos existentes datos.gob.mx\nAhora veamos algunos ejemplos de como interactuar con esos datos mediante la API.\n\n\n\nmuestra el escript:\npacman::p_load(jsonlite, tidyverse, DT, rvest, httr2)\n\nreq &lt;- request(\"https://api.datos.gob.mx/v1/api-catalog?pageSize=10000\")\nresp &lt;- req_perform(req)\n\ndat_1 &lt;- fromJSON(resp_body_string(resp))\ndat_1_df &lt;- dat_1$results\n\nfor (i in 1:length(dat_1_df$variables))\n{\n  dat_1_df$variables[i] &lt;- paste(dat_1_df$variables[[i]], collapse = \",\")\n}\n\ndat_1_df$variables &lt;- unlist(dat_1_df$variables)\n\ndat_1_df |&gt;\n  select(\"endpoint\", \"url\", \"variables\") |&gt; \n  datatable()\n\n\n\n\n\n\n\n\n\nDatos de Ozono como contaminante atmosférico en ciudades de México\nDel catálogo mostrado arriba, obtengo la referencia de la API al conjunto de datos que me interesa, se refiere al endpoint. En este caso se trata del sinaica, la ruta de acceso que me interesa es la URL respectiva. Lo que sigue es agregar los datos específicos que me interesan, que agregaré a la misma URL después de un signo de interrogación.\nLos datos de las estaciones existentes los puedes consultar con la misma API o en la página del Sinaica, Hay un enlace a Infraestructura de los SMCA, que contiene los descriptores de cada una de las estaciones existentes en el país. Para hacerlo con la API buscamos en la tabla anterior sinaica-estaciones. Hacemos la petición así:\n\n\nmuestra el escript:\nURL_estaciones &lt;- \"https://api.datos.gob.mx/v2/sinaica-estaciones?pageSize=1000\"\n\nreq_est &lt;- request(URL_estaciones)\nresp_est &lt;- req_perform(req_est)\n\ndat_est &lt;- fromJSON(resp_body_string(resp_est))\ndat_est_df &lt;- dat_est$results\n\ndat_est_df |&gt;\n  select(\"id\", \"nombre\", \"long\", \"lat\") |&gt; \n  datatable(colnames = c(\"idEstación\", \"nombre\", \"long\", \"lat       \"))\n\n\n\n\n\n\nLas variables que puedo usar para construir esta consulta las encuentro precisamente en la columna variables del catálogo. Para el caso de Sinaica esta columna reporta las siguientes variables disponibles.\n\n\nmuestra el escript:\ndat_1_df |&gt; \n  filter(endpoint == \"sinaica\") |&gt; \n  select(variables) |&gt;  \n  separate_longer_delim(variables,  \",\") |&gt; \n  flextable::flextable() |&gt; \n  flextable::color(i = 7:8 , color = \"blue \")\n\n\nvariables_iddatevalidoorigcitystatevalororigparametroestacionesididhorafecha\n\n\nLos datos que quiero para este ejercicio son el idEstación, y el nombre del parámetro, en este caso O3. Hay un dato pageSize, que se refiere al máximo de registros que esperamos recibir por página. Con estos datos construimos la URL necesaria.\n\nURL: https://api.datos.gob.mx/v2/sinaica\npagesize: 8000\nparametro: O3\nestacionesid: 259 (es la del Pedregal de San ángel, Álvaro Obregón, CdMx)\npage: 1\n\nCombino todos estos parámetros con el caracter & como separador de items y lo agrego todo al final de la URL.El resultado debe verse así.\n\nhttps://api.datos.gob.mx/v2/sinaica?pageSize=8000&parametro=O3&estacionesid=259&page=1\n\n \nAhora, estamos listos para hacer la consulta con el escript de abajo.\n \n\n\nmuestra el escript:\nurl_O3 &lt;- \"https://api.datos.gob.mx/v2/sinaica?pageSize=8000&parametro=O3&estacionesid=259&page=1\"\n\nreq_O3 &lt;- request(url_O3)\nresp_O3 &lt;- req_perform(req_O3)\n\ndat_O3 &lt;- fromJSON(resp_body_string(resp_O3))\ndat_O3_df &lt;- dat_O3$results\n\n\n \nEstos son los datos de ozono en la atmósfera medidos en la estación 259, de la Ciudad de México (Tabla 1).\n \n\n\nmuestra el escript:\ndat_O3_df |&gt;\n  select(\"fecha\", \"hora\", \"valororig\") |&gt; \n  datatable(colnames = c(\"Fecha\", \"Hora\", \"Valor\"))\n\n\n\n\nTabla 1: Ozono atmosférico\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatos de estaciones meteorológicas Conagua\nLos datos generales de todas las estaciones climatológicas de México están publicadas como datos de acceso abierto, pero no están en forrma de tabla sino en forma de datos geográficos asociados a marcadores de puntos que se despliegan en un mapa. Se comprende que es una entrega de datos pensada para que un usuario acceda a la información en forma interactiva. Pienso que para muchos otros fines de reuso de esos datos conviene tenerlos en formato tabular. El documento geográfico está disponible en formato kmz. Este archivo es el tipo que usa Google Earth. Es una versión comprimida como un “zip”, de otro tipo de archivo que es el kml, también desarrollado y usado en Google Earth. Lo que podemos hacer es descomprimir el archivo kmz, y procesar el archivo descomprimido resultante. En R existe la función unzip. Es la que usaremos enseguida.\n\n\nmuestra el escript:\n# descarga el archivo \"kmz\" de interés\nurl_agua &lt;- \"http://smn.conagua.gob.mx/\"\nurl_kmz &lt;- \"tools/RESOURCES/Normales_Climatologicas/EstacionesClimatologicas.kmz\"   \narchivo_kmz &lt;- \"./estaciones.kmz\"\n\nhttr2::request(paste0(url_agua, url_kmz)) |&gt; \n  httr2::req_perform() |&gt; \n  httr2::resp_body_raw() |&gt; \n  writeBin(archivo_kmz)\n\n\n# desempaca el \"kmz\" y guarda el resultado en \"temp-kmz\"\nunzip(zipfile = archivo_kmz, exdir = \"temp-kmz\")\n\n\nLa estrategia de procesamiento que seguiremos la orientaremos a aprovechar el hecho de que los archivos kml son ambién documentos xml, semejantes a los que se usan para producir páginas Web, para manejar este tipo de archivos existe en R la biblioteca rvest que empaca muchas heramientas interesantes para recolectar y procesar datos directamente del Internet (se le llama Web scraping a esta tarea, algo así como ¿cosechar la web?). El proceso require recorrer el documento y recolectar las piezas de información que interesan. La tarea no es sencilla, pero nos sirve de ejemplo avanzado que ilustra cosas que es posile hacer. Una vez obtenidos estos datos podría ser interesante ver formas de análisis de esttos datos generales que te imagines.\nEn el escript que sigue, sólo extraeremos los datos del archivo kml y los desplegaremos en forma de tabla. Los datos quedarán disponibles como una tabla tibble (la variante más moderna del data.frame original de R), que podrás usar de muchas maneras. Me gustará mucho escuchar tus ideas.\n\nEste es el mapa a partir de los datos kmz\n\n\n\nmuestra el escript:\n# carga la biblioteca para procesar el \"xml\"\npacman::p_load(xml2)\n\ndata &lt;- read_html(\"temp-kmz//doc.kml\")\nxml_data &lt;- as_list(data)\n\n# los datoa de interés están en \"folders\" \n# dentro de la rama html/body/kml/document/\nxml_data &lt;- xml_data[[\"html\"]][[\"body\"]][[\"kml\"]][[\"document\"]]\n\n# Estaciones operativas\ndatos_ext_opr &lt;- xml_data[[\"folder\"]][[3]]\n                    \n# Estaciones suspendidas        \ndatos_ext_ssp &lt;- xml_data[[\"folder\"]][[4]]\n\ndatos_todo &lt;- c(datos_ext_opr, datos_ext_ssp)\n\nfor (r in datos_todo)\n{\n  if(!identical(r[[1]],\"Estaciones operativas\") &\n    (!identical(r[[1]],\"Estaciones suspendidas\")))\n  {\n    e &lt;- r$extendeddata$schemadata\n    # recupera datos de la estación \n    nombres &lt;- character(length(e)-1)\n    valores &lt;- character(length(e)-1)\n    for (i in 1:(length(e)-1))\n    {\n        nombres[i] &lt;- attr(e[[i]], \"name\")\n        if (!is_empty(e[[i]])) valores[i] &lt;- e[[i]][[1]]\n    }\n    \n    datos_temp &lt;- tibble(nombres, valores) %&gt;%\n      pivot_wider(names_from = nombres, values_from = valores)\n    \n    if (identical(r, datos_ext_opr[[2]]))\n    {\n      datos_est &lt;- tibble(datos_temp)\n    } else {\n      datos_est &lt;- rows_append(datos_est, datos_temp)\n    }\n  }\n}\n\n\ndatos_est |&gt; \n  select(CLAVE, ESTADO, NOMBRE, SITUACION) |&gt; \n  datatable()\n\n\n\n\nTabla 2\n\n\n\n\n\n\n\n\n\n\n\nLos datos de la estación de Xalapa con id: 30135, son los siguientes.\n\n\n\nmuestra el escript:\n# Datos diarios Xalapa\ndat_csv &lt;- \"ver/dia30135.txt\"\nurl_meteo &lt;- \"https://smn.conagua.gob.mx/tools/RESOURCES/Normales_Climatologicas/Diarios\"\n\nurl_xalapa &lt;- paste(url_meteo, dat_csv, sep = \"/\")\n\ndat_meteo_meta &lt;- readLines(url_xalapa, n = 25)\n\n# datos de la estación\nestacion &lt;- tibble(est = unlist(dat_meteo_meta[11:19])) |&gt; \n  mutate(var = str_extract(est, \"(.*)(?=\\\\s:)\"),\n         val = str_extract(est, \"(?&lt;=\\\\s:)(.*)\"),\n         var = str_trim(var),\n         val = str_trim(val), .keep = \"unused\" ) |&gt;\n  pivot_wider(names_from = var, values_from = val)\n\n\n# variables meteorologicas\nvariables &lt;- str_split(readLines(url_xalapa, n = 24)[24], \"\\t\")[[1]][c(1,3:6)]\n\n# datos meteorológicos\ndat_meteo &lt;- read.csv(url_xalapa, skip = 25, sep = \"\\t\", header = F)\n\nnames(dat_meteo) &lt;- variables\n\ndat_meteo |&gt; \n  mutate(idEstacion = estacion$ESTACIÓN) |&gt; \n  datatable()\n\n\n\n\nTabla 3: Datos meteorológios de Xalapa\n\n\n\n\n\n\n\n\n\n\n\n\nMicrodatos censales\nComo habíamos visto en tipos de estudios Puede interesarte también ete artíulo sobre los datos abiertos que ofrece Inegi y la bilioteca para R que han desarrollado. Este otro es un ejemplo detallado de acceso y procesamiento de microdatos. Algo semejante ofrece este artículo de Castro (2021) y está también el libro completo en línea de Escoto Castillo (2021), sobre como usar microdato para analizar el mercado de tabajo. Si es de tu interés esta página de INEGI te ayudará a encontrar lo que necesitas. Por ejemplo, INEGI dispone de los microdatos del censo agropecuario 2022. Al tratar microdatos es importante que consideres las recomendaciones de seguridad de Griffiths et al. (2020).\n\n\nPrecios según el SNIIM\nMe pareció interesante averiguar sobre mercados en el ámbito agropecuario mexicano. Encontré al SNIIM. Es el Sistema Nacional de Información e Integración de Mercados. Es un servicio que ofrece la Secretaría de Economía con el propósito de poner al alcance sel público información sobre el comportamiento de los precios al por mayor de los productos agrícolas, pecuarios y pesqueros que se comercializan en los mercados nacionales e internacionales.\nDesafortunadamente, la forma como reportan los datos en la página del SNIIM es un poco complicada en términos informáticos y utiliza la tecnología de Microsoft asp.net véase este artículo sobre estas tecnologías. Lo que hacen es generar en forma dinámica una tabla con la información solicitada, pero en lugar de poner los datos en una tabla directamente, producen un iframe, es decir ofrecen sólo una especie de visor a datos que están encapsulados, aunque al desplegar el reporte producido a petición del usuario, parecería que está todo en un sólo documento que se despliega en el navegador, pero no es realmente así.\nPara obtener los datos y poderlos cargar a una tabla en R, es mejor hacer una cosulta directamente a la base de datos. Para eso necesitamos algunos datos específicos que obtendremos de los siguientes catálogos que, con un poco de maña, se pueden obtener del propio sitio del SNIIM, yo ya lo hice por tí y aquí están. A continuación podrás consultar estos catálogos para que contruyas peticiones a tu gusto.\n \n\n\nmuestra el escript:\npacman::p_load(rvest, DT, dplyr, stringr, ggplot2, scales, htmltools)\n\ncat_dest &lt;- read.csv(file = \"sniim-destinos.csv\", quote = \"'\")\ncat_orig &lt;- read.csv(file = \"sniim-origen.csv\")\ncat_frut &lt;- read.csv(file = \"sniim-frutas-hortalizas.csv\")\ncat_flor &lt;- read.csv(file = \"sniim-flores.csv\")\ncat_gran &lt;- read.csv(file = \"sniim-granos-semillas.csv\")\ncat_acei &lt;- read.csv(file = \"sniim-aceite.csv\")\ncat_insu &lt;- read.csv(file = \"sniim-insumo.csv\")\n\ncat_lugar &lt;- cat_dest |&gt; \n  mutate(tipo = \"destino\") |&gt; \n  bind_rows(c(cat_orig, tipo = \"origen\"))\n\ncat_prod &lt;- cat_frut |&gt; \n  mutate(tipo = \"frutas y hortalizas\") |&gt; \n  bind_rows(c(cat_flor, tipo = \"flores\")) |&gt; \n  bind_rows(c(cat_gran, tipo = \"granos y semillas\")) |&gt; \n  bind_rows(c(cat_acei, tipo = \"aceites comestibles\")) |&gt; \n  bind_rows(c(cat_insu, tipo = \"insumos agrícolas\"))\n\n\n\n\nLugar de Orígen y Mercado de Destino\n\n\nmuestra el escript:\ncat_lugar |&gt; \n  datatable() #options = list(pageLength = 1)) #, caption = tags$caption(style = \"caption-side: top; text-align: center; font-weight: bold;\", \"Mercado de Destino\"))\n\n\n\n\n\n\n\n\n\nProductos en los Mercados Agrícolas Nacionales\n\n\nmuestra el escript:\ncat_prod |&gt; \n  datatable()\n\n\n\n\n\n\n\n\n\nHagamos un ejercicio con los precios del limón sin semilla en Xalapa, entre las fechas 01/feb/2025 y 01/abr/2025. Para hacer esto necesitamos los siguientes datos.\n\nurl base: http://www.economia-sniim.gob.mx/nuevo/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas/\nescript de consulta:ResultadosConsultaFechaFrutasYHortalizas.aspx\ngenerador de la tabla de datos: ResultadosConsultaFechaFrutasYHortalizas.aspx \nfechaInicio: 01/01/2025  fechaFinal: 01/04/2025  ProductoId 426  OrigenId 30  Origen Veracruz  DestinoId 301  Destino Veracruz: Central de Abasto de Jalapa  PreciosPorId 2 (este código se refiere a kg unitario)  RegistrosPorPagina 500  \n\nAhora, semejante a los ejemplos anteriores, tomamos la URL base y, en este caso, la juntamos con la llamada al escript que se encarga de hacer la consulta a la base de datos y le ponemos una iterrogación al final. Luego hacemos la consulta que nos interesa, agregando los datos separados por el símbolo &. Todo en una sola larga línea. Así:\n\nhttp://www.economia-sniim.gob.mx/nuevo/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas/ResultadosConsultaFechaFrutasYHortalizas.aspx?fechaInicio=01/02/2025&fechaFinal=01/04/2025&ProductoId=426&OrigenId=30&Origen=Veracruz&DestinoId=301&Destino=Veracruz: Central de Abasto de Jalapa&PreciosPorId= 2&RegistrosPorPagina=500\n\nEn general no conviene usar espacios entre palabras en las URL, así que se suelen substituir por el código %20. Si tu consulta llegara a fallar, esta es una cosa que podrías intentar, pero antes checa que todo se vea según tu plan. Por cierto, notarás que cada elemento de la consulta tiene un nombre de parámetro y un valor, separados por el signo “=”. Normalmente esto sugiere que el orden en el que pongas las cosas no importa, salvo la parte que está antes de la interrogación. Aquí hay algo de documentación de este servicos gubernamental.\nListo, hagamos la consulta para averiguar el patrón de precios del limón sin semilla en lo que va de 2025 en Xalapa, Ver.\n \n\n\nmuestra el escript:\nurl_limon &lt;- \"http://www.economia-sniim.gob.mx/nuevo/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas/ResultadosConsultaFechaFrutasYHortalizas.aspx?fechaInicio=01/01/2025&fechaFinal=01/04/2025&ProductoId=426&OrigenId=30&Origen=Veracruz&DestinoId=301&Destino=Veracruz:%20Central%20de%20Abasto%20de%20Jalapa&PreciosPorId=2&RegistrosPorPagina=500\"\n\npage &lt;- read_html(url_limon)\n\ntabla_precios &lt;- page %&gt;% \n  html_node(\"table#tblResultados\") %&gt;%\n  html_table(header = TRUE) %&gt;% \n  slice(-1) %&gt;% \n  mutate(precio_num = as.numeric(`Precio Frec`),\n         feha_d = as.Date(Fecha, format = \"%d/%m/%Y\")) %&gt;% \n  rename_with(., ~ str_replace_all(iconv(.x, to='latin1//TRANSLIT'), \"'\", \"\"))\n\n# print result to console\n\ntabla_precios |&gt;\n  select(Fecha:Obs.) |&gt; \n  datatable()\n\n\n\n\n\n\nmuestra el escript:\ntabla_precios |&gt; \n  ggplot(aes(x = feha_d, y = precio_num)) +\n    geom_point() +\n    geom_smooth(method = 'loess', formula = 'y ~ x', span = 0.3) +\n    labs(title = \"Precio del limón sin semilla\", \n         subtitle = \"Xalapa, Ver. entre 1/ene/2025 y 1/abr/2025\") +\n    xlab(label = \"Fecha\") +\n    ylab(label = \"Precio ($ mn/kg)\") +\n    scale_x_date(labels = date_format(\"%b-%Y\", locale = \"es\"))"
  },
  {
    "objectID": "posts/2025-02-28-contenido/index.html#platiquemos-sobre-tus-intereses",
    "href": "posts/2025-02-28-contenido/index.html#platiquemos-sobre-tus-intereses",
    "title": "¿Qúe puedo incluir en mis documentos?",
    "section": "Platiquemos sobre tus intereses",
    "text": "Platiquemos sobre tus intereses\nTu Blog contendrá alguno o varios de los siguientes componentes:\n\nTablas de datos.\nGráficas.\nMapas.\nAnálisis de datos geográficos.\nAnálisis de series de tiempo.\nModelos matemáticos.\nAnálisis estadísticos.\nAnálisis de datos moleculares.\nAnálisis de imágenes.\nAnálisis de audio.\nAlguna otra cosa que sea de tu interés.\n\nSugiero hacer una reflexión sobre esto y considerar también de qué manera se obtendrán los datos, procesarán y presentarán.\n\nAlgunas ideas para animar la charla\nUna cosa que podría ser de tu interés es cosechar datos del Internet. R tiene bibliotecas bbastante competenes para hacerlo, pero te invito primero a pensarlo y precisar la idea, para entonces dedicar alguna sesión del taller en el futuro próximo al tema. Junto con esto va una reflexión sobre datos abiertos que tengo previsto tratar y junto con esto alguunos asuntos sobre derechos de autor y licenciamiento del contenido que tu mismo producirás. En tanto resolvemos esta interés, una cosa más sencilla es trabajar con datos que ya tengo en mi poseción, es decir un Excel o documento semejante en mi máquina."
  },
  {
    "objectID": "posts/2025-02-28-contenido/index.html#datos-en-mi-equipo",
    "href": "posts/2025-02-28-contenido/index.html#datos-en-mi-equipo",
    "title": "¿Qúe puedo incluir en mis documentos?",
    "section": "Datos en Mi equipo",
    "text": "Datos en Mi equipo\nObviamente, la forma más sencilla de acceder a datos es cuando los tenemos en nuestro propio equipo. En este caso lo usual es que sea alguno de los formatos de Microsoft (Word o Excel) o algún formato genérico como los identificados como txt (texto plano) o csv (valores separados por comas). Puuede haber otras variantes de archivos de datos, como kml, GeoJson, GeoTIFF o shp (shape file) usuales en la gestión de datos geográficos. En Genómica está el formato fasta, que también cuenta con bibliotecas adecuadas en R. Hay una correspondiente variedad de recursos para leer todos estos tipos de datos en R así como para analizarlos y preparar resúmenes, modelos y gráficos de interés. A continuación veremos algunos ejemplos sencillos para tener una idea del proceso general. Para nuestros fines didácticos veamos como leer datos de Excel.\n\nDatos Excel\nTengo este archivo de datos obtenidos por D.L. Cunningham de la Universidad de Cornell. Son registros de masa corporal (g) de pollos de acuerdo con su posición en la jerarquía de picotazos (Tabla 1). Veamos los datos. En el procceso de demostración también te comparto como construir una tabla en formato publicable con la biblioteca flextable. Otra posibilidad para trabajar tablas es la biblioteca DT, más orientada a construir tablas que serán utilizadas en forma interactiva.\nAquí están los datos\n\n\nmuestra el escript:\npacman::p_load(tidyverse, ggplot2, readxl, flextable)\n\npollos_peso &lt;- read_excel(\"datos/peck_odr.xls\", skip = 2)\n\npollos_peso |&gt;\n  flextable() |&gt; \n  width(j = 2:8, width = 25, unit = \"mm\") |&gt; \n  set_header_labels(\"Jerarquía\\npor picoteo\" = \"Posición\",\n                    gallinero = \"Gallinero\",\n                    peso = \"Peso\\n(g)\")\n\n\n\n\nTabla 1: Jearquía de Picotazos\n\n\n\nPosiciónGallinero 1Gallinero 2Gallinero 3Gallinero 4Gallinero 5Gallinero 6Gallinero 711,8801,3001,6001,3801,8001,0001,68021,9201,7001,8301,5201,7801,7401,46031,6001,5001,5201,5201,3601,5201,76041,8301,8801,8201,3802,0002,0001,800\n\n\n\n\n\nLos datos están en un formato poco conveniente para un análisis general. Hagamos algunas operaciones para ponerlos en una forma más adecuada. Básicamente buscaremos cambiar del formato extendido, bueno para visualizar, a uno apilado, más apropiado para el análisis estadístico.\n\n\nmuestra el escript:\npollos_peso &lt;- pollos_peso %&gt;%\n                 rename(jerarquia = `Jerarquía\\npor picoteo`) %&gt;% \n                 pivot_longer(cols = `Gallinero 1`:`Gallinero 7`, \n                              names_to = \"gallinero\",\n                              values_to = \"peso\") %&gt;% \n                 mutate(gallinero = factor(gallinero),\n                        jerarquia = as.integer(jerarquia)) %&gt;% \n                 arrange(gallinero)\n\n\n\nAprovecharé la nueva disposición para demostrar el uso de la biblioteca DT que define la función datatable y un montón de otros recursos para dar formato tabular y anotar los datos de interés.\n\n\n\nmuestra el escript:\nlibrary(DT)\n\npollos_peso |&gt; \n  datatable(colnames = c(\"Posición\", \"id-Gallinero\", \"Peso\")) \n\n\n\n\n\n\n\n\nOtra cosa que puedo hacer ahora es construir un gráfico con los datos utilizando la bibliotea ggplot2, muy capáz de producir gráficos atractivos, incluso como para publicaciones formales. Piensa en qué gráficos te gustaría inlcuir en el blog que estas construyendo. En este enlace encontraras una galería de gráficos que pueden ayudar a estimular tu imaginación e interés.\n\n\n\nmuestra el escript:\nggplot(pollos_peso, aes(x = jerarquia, y = peso)) +\n  geom_point(color = \"darkgreen\")\n\n\n\n\n\n\n\n\n\n\n¿qué análisis sugieres habría que hacer ahora? ¿Cómo lo presentarías para asegurar que tu proceso analítico sea reproducible?"
  },
  {
    "objectID": "posts/2025-02-28-contenido/index.html#un-bonito-mapa",
    "href": "posts/2025-02-28-contenido/index.html#un-bonito-mapa",
    "title": "¿Qúe puedo incluir en mis documentos?",
    "section": "Un bonito mapa",
    "text": "Un bonito mapa\n¿Piensas que hacer mapas impactantes es cosa de una élite entrenada en GIS? Quizás la belleza de muchos mapas que encontramos por ahí justifica pensar así. Pero ahora podemos aspirar a incluir hermosos mapas en nuestros documentos, pues el acceso a recursos abiertos muy competentes de mapeo ha cambiado mucho. En R tenemos ahora bibliotecas como sf, raster, terra, leaflet, ggplot2 y tmap, además del software especializado QGIS,\nCon leaflet incluir mapas, incluso interactivos, es bastante sencillo. Veamos como empezar con esta biblioteca con unas breves instrucciones.\n\n\nmuestra el escript:\nlibrary(leaflet) # cargar la biblioteca requerida.\n\nbasemap &lt;- leaflet() %&gt;%\n  # ubicación de la zona de interés y nivel de zoom inicial\n  setView(lng = -96.91841, lat = 19.515157, zoom = 20) %&gt;% \n\n    # Añade proveedor de mapa\n  addProviderTiles(\"OpenStreetMap\",\n                     \n    # Dale un nombre a la capa\n    group = \"Mapa-OpenStreet\"\n  )\n\n# despliega el mapa\nbasemap \n\n\n\n\n\n\n   \nAgregar capas, marcadores, etc. Tampoco es muy complicado. Veamos un ejemplo.\n   \n\n\nmuestra el escript:\nicon.fa &lt;- makeAwesomeIcon(icon = \"bicycle\", markerColor = \"green\",\n                           library = \"fa\",\n                           iconColor = \"red\")\n\n\nmap_1 &lt;- basemap %&gt;% \n  addProviderTiles(\"Esri.WorldImagery\", \n                   group = \"ESRI\") %&gt;% \n  addWMSTiles(\n    \"http://gaia.inegi.org.mx/NLB/tunnel/wms/wms61?\",\n    layers = \"Ortofotos\",\n    options = WMSTileOptions(format = \"image/png\", transparent = TRUE),\n    attribution = \"Inegi\",\n    group = \"Inegi-ortofoto\") %&gt;% \n  addWMSTiles(\n    \"http://gaia.inegi.org.mx/NLB/tunnel/wms/wms61?\",\n    layers = \"c407\",\n    options = WMSTileOptions(format = \"image/png\", transparent = TRUE),\n    attribution = \"Inegi\",\n    group = \"Humedad del suelo\") %&gt;% \n  addAwesomeMarkers(\n    lat = 19.5152,\n    lng = -96.91841,\n    label = \"Starting point\",\n    icon = icon.fa\n  ) %&gt;% \n\n  # Layers control\n  addLayersControl(\n    baseGroups = c(\n      \"Mapa-OpenStreet\",\n      \"ESRI\",\n      \"Inegi-ortofoto\",\n      \"Humedad del suelo\"\n    ),\n    options = layersControlOptions(collapsed = FALSE)\n  )\n\nmap_1\n\n\n\n\n\n\n\n\nOtra posibilidad para producir documentos con mapas más bien de tipo impreso es la biblioteca tmap podemos hacer cosas como las siguiente. Usaremos los datos contenidos en el paquete spData para ejemplificar. Aquí está un tutorial sobre esta biblioteca.\n\n\n\n\nmuestra el escript:\nlibrary(tmap)\nlibrary(spData)\nlibrary(dplyr)\n\ndata(\"urban_agglomerations\")\n\nurb_1970_2030 &lt;-  urban_agglomerations %&gt;% \n  filter(year %in% c(1970, 1990, 2010, 2030))\n\ndata(\"World\")\n\ntm_shape(World) +\n  tm_polygons(fill = \"lightblue\") +\n  tm_crs(\"auto\") +\n  tm_shape(urb_1970_2030, ) +\n  tm_symbols(fill = \"black\", \n             col = \"white\", \n             size = \"population_millions\", \n             size.legend = tm_legend(title = \"Población (millones)\")) +\n  tm_facets_wrap(by = \"year\", nrow = 2)\n\n\n\n\n\n\n\n\n\n\nA pesar de lo dicho arriba, con esta biblioteca también se puede incursionar en preparar productos geográficos dinámicos, como sería una animación.\n\n\n\nmuestra el escript:\nurb_anim &lt;- tm_shape(World) + \n  tm_polygons() + \n  tm_crs(\"auto\") +\n  tm_shape(urban_agglomerations) + \n  tm_symbols(size = \"population_millions\", fill = \"green\") +\n  tm_facets_wrap(by = \"year\", nrow = 1, ncol = 1, free.coords = FALSE) \n\nanim &lt;- urb_anim %&gt;%     \n  tmap_animation(filename = \"img/urb_anim.gif\", delay = 45, verbose = false);\n\n\nCreating frames\n\n\n\nCreating animation\nAnimation saved to C:\\Users\\equih\\0 Versiones\\ciencia-reproducible\\2025\\posts\\2025-02-28-contenido\\img\\urb_anim.gif \n\n\nmuestra el escript:\nknitr::include_graphics(\"img/urb_anim.gif\")"
  },
  {
    "objectID": "posts/2025-02-28-contenido/index.html#incluir-videos",
    "href": "posts/2025-02-28-contenido/index.html#incluir-videos",
    "title": "¿Qúe puedo incluir en mis documentos?",
    "section": "Incluir videos",
    "text": "Incluir videos\nSi por cualquier razón encuentras justificado o importante mostrar algo que está en forma de video, fácilmente puedes agregarlo a tu blog. Tan simple como poner algo semejante a esto directamente en el texto. Es decir no se requiere un trozo de código ( code chunk).\n\\(\\{\\{&lt;\\) video https://youtu.be/wo9vZccmqwc start=“10” \\(&gt;\\}\\}\\)"
  },
  {
    "objectID": "posts/2025-02-28-contenido/index.html#datos-mediante-captura-con-el-celular",
    "href": "posts/2025-02-28-contenido/index.html#datos-mediante-captura-con-el-celular",
    "title": "¿Qúe puedo incluir en mis documentos?",
    "section": "Datos mediante captura con el celular",
    "text": "Datos mediante captura con el celular\nUsar las plataformas móbiles para capturar datos en campo tiene una historia que va a los primeros dispositivos llamados PDA (Personal Digital Assistant) allá por los mediados de 1990. Siguieron los avances que condujeron a la aparición del iPhone® y del sistema Android®. La aparición de Android incentivó el desarrollo que apareció en 2010 como Open Data Kit (ODK). Un poco más adelante un grupo de la Universidad de Harvard desarrolló la aplicación Kobo, basada en el mismo motor de software de ODK, pero con una estrategia de servico distinta. En cualquier caso, para la adquisición de datos en campo la base ODK es sin duda un estandar mundial (Brunette & Hartung, 2023; Hartung et al., 2010). No quiero entrar en los detalles de cada solución, sólo quiero que conozcas de su existencia, para saber más de ellas puedes ir a sus respectivos sitios Web: odkcloud y kobotoolbox. Hay bibliotecas en R para acceder a cualquiera de estas dos soluciones: ruODK, odkr y KoboconnectR, por ejemplo.\nOtra opción interesante está en proceso de desarrollo actualmente. La encuentro viable como para satisfacer las neesidades de proyectos muy pequeños en estos momentos. Se trata de los recursos que ofrece la biblioteca surveydown. Aquí te dejo un tutorial de ejemplo sobre como aprovechar este paquete desde Quarto."
  },
  {
    "objectID": "posts/2025-02-28-contenido/index.html#lecturas-sugeridas",
    "href": "posts/2025-02-28-contenido/index.html#lecturas-sugeridas",
    "title": "¿Qúe puedo incluir en mis documentos?",
    "section": "Lecturas sugeridas",
    "text": "Lecturas sugeridas\n\nBrunette, W., & Hartung, C. (2023). The Open Data Kit Project. En T. Madon, A. J. Gadgil, R. Anderson, L. Casaburi, K. Lee, & A. Rezaee (Eds.), Introduction to Development Engineering: A Framework with Applications from the Field (pp. 613-637). Springer International Publishing. https://doi.org/10.1007/978-3-030-86065-3_23\n\n\nHartung, C., Lerer, A., Anokwa, Y., Tseng, C., Brunette, W., & Borriello, G. (2010). Open data kit: tools to build information services for developing regions. Proceedings of the 4th ACM/IEEE International Conference on Information and Communication Technologies and Development, 1-12. https://doi.org/10.1145/2369220.2369236"
  },
  {
    "objectID": "posts/2025-04-24-paper-typst/articulo-pizza.html",
    "href": "posts/2025-04-24-paper-typst/articulo-pizza.html",
    "title": "La Mejor Masa de Pizza para Marcelo",
    "section": "",
    "text": "This document shows a practical usage of the template.\nI use the Palmer penguins dataset (Horst, Hill, y Gorman 2020) to demonstrate the features of the template. The code is available here."
  },
  {
    "objectID": "posts/2025-04-24-paper-typst/articulo-pizza.html#subsection-as-heading-level-2",
    "href": "posts/2025-04-24-paper-typst/articulo-pizza.html#subsection-as-heading-level-2",
    "title": "La Mejor Masa de Pizza para Marcelo",
    "section": "Subsection as Heading Level 2",
    "text": "Subsection as Heading Level 2\nYou can use LaTeX math expressions:\n\\[\nY_{it} = \\alpha_i + \\lambda_t + \\sum_{k \\neq -1} \\tau_h \\mathbb{1}\\{E_i + k = t\\} +\n\\varepsilon_{it}.\n\\]\nI choose a mathematical font which supports the indicator function \\(\\mathbb{1}\\{\\cdot\\}\\). Currently, I use the ?meta:mathfont font.\n\nSubsubsection as Heading Level 3\nI don’t use and don’t recommend using heading levels 3 and below but it works."
  },
  {
    "objectID": "posts/2025-04-24-paper-typst/articulo-pizza.html#citation",
    "href": "posts/2025-04-24-paper-typst/articulo-pizza.html#citation",
    "title": "La Mejor Masa de Pizza para Marcelo",
    "section": "Citation",
    "text": "Citation\nYou can cite a reference like this (Katsushika 1831) or Horst, Hill, y Gorman (2020). Typst has some built-in citation styles. Check the Typst documentation for more information."
  },
  {
    "objectID": "posts/2025-04-24-paper-typst/articulo-pizza.html#figures",
    "href": "posts/2025-04-24-paper-typst/articulo-pizza.html#figures",
    "title": "La Mejor Masa de Pizza para Marcelo",
    "section": "Figures",
    "text": "Figures\nAs Figura 1 shows, the caption is displayed below the figure. As a caption of the figure (fig-cap), I use bold text for the title and use a normal text for the description.\n\n\n\n\n\n\n\n\nFigura 1: Flipper Length and Bill Length of Penguins. The x-axis shows the flipper length, and the y-axis shows the bill length.\n\n\n\n\n\nWhen I want to show multiple figures side by side, I use the patchwork package. The reason why I don’t use the layout-col option is that the caption is also split into two parts.\n\n\n\n\n\n\n\n\nFigura 2: Characteristics of Penguins. The left panel shows the relationship between flipper length and body mass. The right panel shows the density of flipper length."
  },
  {
    "objectID": "posts/2025-04-24-paper-typst/articulo-pizza.html#tables",
    "href": "posts/2025-04-24-paper-typst/articulo-pizza.html#tables",
    "title": "La Mejor Masa de Pizza para Marcelo",
    "section": "Tables",
    "text": "Tables\nYou can use tinytable for general tables and modelsummary for regression tables. As Tabla 1 shows, the caption is displayed above the table. The notes of the table can be added using the notes argument of the tinytable::tt() function.\n\n\n\n\nTabla 1: Summary Statistics of Penguins\n\n\n\n\n\n    \n\n    \n    \n      \n        \n\n \nMale\nFemale\n\n        \n              \n                \n                Bill Length (mm)\n                Bill Depth (mm)\n                Flipper Length (mm)\n                Body Mass (g)\n                Bill Length (mm)\n                Bill Depth (mm)\n                Flipper Length (mm)\n                Body Mass (g)\n              \n        \n        _Notes_: Data from Palmer penguins dataset.\n        \n                \n                  Adelie\n                  40.39\n                  19.07\n                  192.4\n                  4043\n                  37.26\n                  17.62\n                  187.8\n                  3369\n                \n                \n                  Gentoo\n                  49.47\n                  15.72\n                  221.5\n                  5485\n                  45.56\n                  14.24\n                  212.7\n                  4680\n                \n                \n                  Chinstrap\n                  51.09\n                  19.25\n                  199.9\n                  3939\n                  46.57\n                  17.59\n                  191.7\n                  3527\n                \n        \n      \n    \n\n\n\n\n\n\nSince the default backend of modelsummary is tinytable, you can use the customization options of tinytable for modelsummary. In Tabla 2, I use tinytable::group_tt() function to group the regression results by the dependent variables\n\n\n\n\nTabla 2: Regression Results of Penguins\n\n\n\n\n\n    \n\n    \n    \n      \n        \n\n \nBill Length (mm)\nBody Mass (g)\n\n        \n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n                (5)\n                (6)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01\n_Notes_: Data from Palmer penguins dataset.\n        \n                \n                  Chinstrap\n                  10.042**\n                  10.010**\n                  10.037**\n                  32.426\n                  26.924\n                  27.229\n                \n                \n                  \n                  (0.432)\n                  (0.341)\n                  (0.340)\n                  (67.512)\n                  (46.483)\n                  (46.587)\n                \n                \n                  Gentoo\n                  8.713**\n                  8.698**\n                  8.693**\n                  1375.354**\n                  1377.858**\n                  1377.813**\n                \n                \n                  \n                  (0.360)\n                  (0.287)\n                  (0.286)\n                  (56.148)\n                  (39.104)\n                  (39.163)\n                \n                \n                  Male\n                  \n                  3.694**\n                  3.694**\n                  \n                  667.555**\n                  667.560**\n                \n                \n                  \n                  \n                  (0.255)\n                  (0.254)\n                  \n                  (34.704)\n                  (34.755)\n                \n                \n                  Year\n                  \n                  \n                  0.324*\n                  \n                  \n                  3.629\n                \n                \n                  \n                  \n                  \n                  (0.156)\n                  \n                  \n                  (21.428)\n                \n                \n                  Observations\n                  342\n                  333\n                  333\n                  342\n                  333\n                  333\n                \n        \n      \n    \n\n\n\n\n\n\nWhile tinytable generates compatible tables between LaTeX and Typst, it does not support LaTeX math expressions for Typst tables. I think the compatibility between LaTeX and Typst is crucial for academic writing because it guarantees that the document can be easily converted to LaTeX for submission to journals.\nA workaround is to use MiTeX, a Typst package that allows you to use LaTeX math expressions in Typst. I write a custom theme for tinytable to convert LaTeX math expressions to MiTeX expressions. The following table includes LaTeX math expressions but will be converted to MiTeX expressions in the Typst output.\n\n\n\n\nTabla 3: Math Symbols\n\n\n\n\n\n    \n    \n    \n    \n\n    \n\n    \n    \n      \n        \n        \n              \n                Math\n              \n        \n        \n        \n                \n                  $\\alpha$\n                \n                \n                  $a_{it}$\n                \n                \n                  $e^{i\\pi} + 1 = 0$"
  },
  {
    "objectID": "posts/2025-04-04-dar-formato-al-texto/index.html",
    "href": "posts/2025-04-04-dar-formato-al-texto/index.html",
    "title": "Dar formato a mi documeto",
    "section": "",
    "text": "Voy a empezar por mi propia reacción “no me gustó la configuración default que usa Quarto”, en cuanto a justificar a la izquierda las leyendas de las figuras. Para cambiar eso use el código del Listado 1, dentro de un trozo de código css:\nEsto tiene un poco que ver con el asunto de darle en general un tema/aspecto al proyecto. Aquí puedes encontrar más información al respecto. Para cambiar el tema modifica el archivo _quarto.yml en la línea de theme (Figura 2). Por cierto, nota que en esta figura aparece la opción lightbox. Esa opción es la que activa la función que permite interactuar con las ilustraciones como entidades separadas, para que el usuario pueda explorarlas con más detalle.\nOtra cosa que puede interesarte hacer es controlar el arreglo general de la página de tu blog (Figura 3). Algo que puedes hacer en el documento general _quarto.yml. Aquí están los detalles. Por cierto, el componente about del blog tiene sus propios estilos, pues se asume que debe acomodar datos personales, biográficos, etc. Puedes encontrar más información al respecto en esta parte de la documentación de Quarto."
  },
  {
    "objectID": "posts/2025-04-04-dar-formato-al-texto/index.html#imágenes-en-el-margen",
    "href": "posts/2025-04-04-dar-formato-al-texto/index.html#imágenes-en-el-margen",
    "title": "Dar formato a mi documeto",
    "section": "Imágenes en el margen",
    "text": "Imágenes en el margen\nPara hacer esto hay que escribir así:\n\n\n\n:::{.column-margin}   \n![](img/door-575958_1280.png){width=200} \n:::\npara obtener este resultado."
  },
  {
    "objectID": "posts/2025-04-04-dar-formato-al-texto/index.html#crear-columnas",
    "href": "posts/2025-04-04-dar-formato-al-texto/index.html#crear-columnas",
    "title": "Dar formato a mi documeto",
    "section": "Crear Columnas",
    "text": "Crear Columnas\nA veces nos gustaría tener una figura al lado del texto o como en un periódico o revista, tener el texto en columnas angostas. Esto es bastante fácil de lograr en Quarto. Hay varias maneras de hacerlo. la más sencilla:\n:::{layout=\"[1,1]\"}\nPárrafo 1 con algunas ideas muy sabias... \n\nPárrafo 2 para explicar lo sabio del párrafo 1...\n:::\nLos número dentro de paréntesis cuadrados indican proporción, no una magnitud absoluta. En este caso, dos columnas del mismo tamaño. Puedes usar valores negativos para abrir espacios entre columnas. El resultado se ve así:\n\n\n\n\n\n\nPárafo 1 con algunas ideas muy sabias. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n\n\nPárrafo 2 para explicar lo sabio del párrafo 1. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n\n\n\nOtra manera es la siguiente.\n:::.columns}\n::::{.column width=\"40%\"}\nPárrafo 1 con algunas ideas muy sabias... \n::::\n   \n::::{.column width=\"60%\"}\nPárrafo 2 para explicar lo sabio del párrafo...\n::::\n:::\n\n\nPárafo 1 con algunas ideas muy sabias. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n\nPárrafo 2 para explicar lo sabio del párrafo 1. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n\n\nIntenta usar esto para producir un texto al lado de una imágen. ¿Con cuál variante te sientes más cómoda o cómodo?"
  },
  {
    "objectID": "posts/2025-04-04-dar-formato-al-texto/index.html#identificadores-fijos",
    "href": "posts/2025-04-04-dar-formato-al-texto/index.html#identificadores-fijos",
    "title": "Dar formato a mi documeto",
    "section": "Identificadores fijos",
    "text": "Identificadores fijos\nQuarto tiene prevista toda una colección de identificadores para reconocer los distintos tipos de componentes que pueden requerir alguna forma de llamada en el texto. Claramente es el caso de figuras y tablas. Pero Quarto tiene además toda una gama de componentes que son susceptibles de referencia cruzada. Los anoto en el Tabla 1. Algunos de ellos corresponden con bloques de llamada (callouts), que desde luego también puede ser interesante referir en otras partes del texto y que podrían tener contenido distinto al sugerido por el bloque. Por ejemplo, dentro de un bloque tip, podría ponerse una definición a la que se hace referencia en otra parte del texto. Además, podrías definir tu propio prefijo para llevar control de alguna clase de componente de t interés. Puedes encontrar más al respecto en la documentación de Quarto.\n \n\n\n\nTabla 1: Lista de prefijos previstos en Quarto.\n\n\n\n\n\nPrefijo\nComponente\n\n\n\n\n{tu clave}\n{tus términos}\n\n\ncau\nprecaución\n\n\ncnj\nconjetura\n\n\ncor\ncorolario\n\n\ndef\ndefinición\n\n\neq\necuación\n\n\nexm\nejemplo\n\n\nexr\nejercicio\n\n\nfig\nfigura\n\n\nimp\nimportante\n\n\nlem\nlema\n\n\nlst\ncódigo de cómputo\n\n\nnte\nnotas\n\n\nprp\nproposición\n\n\nrem\nobservación\n\n\nsec\nsección\n\n\nsol\nsolución\n\n\ntbl\ncuadro\n\n\nthm\nteorema\n\n\ntip\nsugerencia\n\n\nwrn\nadvertencia\n\n\n\n\n\n\n \nUsa esos prefijos según se requiera y aplica el concepto de marcar la definición de la refenencia con # y su llamada con @. Ve el ejemplo siguiente. Quiero incluir la definición de algo de interés (Definición 1 - aquí use @def-definir para hacer la llamada). Esta llamada hace referencia a esto, que puedo poner en cualquier lugar del documento.\n \n\n::: {#def-definir}\nDefinición de algo importante\n:::\n\n\n \nEste texto se verá así en donde quiera que lo pongas.\n\n\nDefinición 1 Definición de algo importante\n\n\n   \nPuede ser que interese hacer referencia a un poco de código computacional que es importante en la explicación de tus hallazgos científicos o tecnológicos. Por ejemplo, el Listado 2 es el que use para producir la Figura 4. Se trata de una ilustración de la taxonomía de características de sabor que pueden apreciarse en una taza de café. La gráfica de la izquierda son datos un poco resumidos y los de la derecha una lista llamada completa. La presentación permite comparar ambos conjuntos de datos.\n \n\n\n\nListado 2: Código para producir una gráfica bonita.\n\n\n\n\nmuestra el escript:\nlibrary(plotly, warn.conflicts = FALSE, quietly = TRUE, mask.ok = TRUE)\n\nd1 &lt;- read.csv('https://raw.githubusercontent.com/plotly/datasets/master/coffee-flavors.csv')\nd2 &lt;- read.csv('https://raw.githubusercontent.com/plotly/datasets/718417069ead87650b90472464c7565dc8c2cb1c/sunburst-coffee-flavors-complete.csv')\nfig &lt;- plot_ly() \nfig &lt;- fig %&gt;%\n  add_trace(\n    ids = d1$ids,\n    labels = d1$labels,\n    parents = d1$parents,\n    type = 'sunburst',\n    maxdepth = 2,\n    domain = list(column = 0)\n    ) \nfig &lt;- fig %&gt;%\n  add_trace(\n    ids = d2$ids,\n    labels = d2$labels,\n    parents = d2$parents,\n    type = 'sunburst',\n    maxdepth = 3,\n    domain = list(column = 1)\n  ) \nfig &lt;- fig %&gt;%\n  layout(autosize=F, width = 700, height = 450, \n         grid = list(columns =2, rows = 1),\n         margin = list(l = 0, r = 0, b = 0, t = 0),\n         sunburstcolorway = c(\"#636efa\",\"#EF553B\",\"#00cc96\",\n                              \"#ab63fa\",\"#19d3f3\",\"#e763fa\",\n                              \"#FECB52\",\"#FFA15A\",\"#FF6692\",\n                              \"#B6E880\"),\n      extendsunburstcolors = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nFigura 4: Gráfica dinámica bonita con biblioteca Plotly"
  },
  {
    "objectID": "posts/2025-04-04-dar-formato-al-texto/index.html#bloques-tipo-caja",
    "href": "posts/2025-04-04-dar-formato-al-texto/index.html#bloques-tipo-caja",
    "title": "Dar formato a mi documeto",
    "section": "Bloques tipo “caja”",
    "text": "Bloques tipo “caja”\nA veces conviene ofrecer información adicional al lector, dándole la oportunidad de decidir cuándo o si es que la desea ver. Hay una colección de cajas de este tipo en Quarto que se engloban en el conjunto callout. Su uso es mediante fences (div), el sistema de marcado que se inicia con ::: {_indicación_} y se cierra con :::.\n\n\n\ntipo\nllamada\n\n\n\n\nnote\n::: {.callout-note}\n\n\nwarning\n::: {.callout-warning}\n\n\nimportant\n::: {.callout-important}\n\n\ntip\n::: {.callout-tip}\n\n\ncaution\n::: {.callout-caution}\n\n\n\nEn cada uno de estos casos puedes agregar la frase: collapse=\"true\". Al hacerlo, el bloque aparecerá cerrado y el lector deberá activarlo para leer su contenido. Puedes también agregar un título con la frase title=\"Tip with Title\" o si anotas un texto con marcado de sub título en seguida de la llamada.\n\n\n::: {.callout-tip}\n## Título de un bloque de “sugerencias”\nAlgo que sea importante decir, ¡pero no indispensable!\n:::\n\n\nLa marcas de estos bloques pueden anidarse, en cuyo caso habrá que cuidar que el número de veces que aparece : sea el mismo al abrir y cerrar el bloque respectivo. Algo así:\n\n\n::: {inicia 1}\n:::: {inicia B}\nalgo de contenido\n::::\n:::"
  },
  {
    "objectID": "posts/2025-04-04-dar-formato-al-texto/index.html#formato-del-texto",
    "href": "posts/2025-04-04-dar-formato-al-texto/index.html#formato-del-texto",
    "title": "Dar formato a mi documeto",
    "section": "Formato del texto",
    "text": "Formato del texto\nSe puede usar la opción style que admite varios componentes:\n::: {style=“font-size: 50%; color:green; font-family: helvetica; font-size:44px;”}\nEsto también se puede hacer a nivel incluso de una letra con la idea siguiente:\n[rojo]{style=“color:red;”}.\nPuede interesarte una referencia a como definir los colores. Hay muchas posibilidades en la Web, pero está es un inicio. Con esta página conseguiras el código hexadecimal, el que está marcado con #. Lo puedes usar así:\n[rojo]{style=“color:#E71D02;”}\nMuchos colores tienen nombres definidos, si lo prefieres puedes usarlos en lugar del código hexadecimal.\nOtra opción del atributo style es la forma de justificación de un texto. La frase a usar es text-align: justify. Las variantes de justificación son las usuales: justify, center, right, left. Si quieres profundizar más en todo esto te sugiero empezar aquí\n\nLorem ipsum dolor sit amet consectetur adipiscing elit, augue rutrum feugiat vitae habitasse nisi aenean tellus, suspendisse malesuada faucibus nam dapibus id. Gravida felis dictumst at nibh lacinia ut hendrerit euismod pellentesque, scelerisque sed conubia commodo iaculis luctus tristique rhoncus, velit eleifend purus class non rutrum odio placerat. Integer sagittis magnis lacus erat senectus lobortis aliquet sodales, dignissim convallis conubia arcu pretium suscipit a torquent faucibus, velit laoreet maecenas auctor vivamus morbi netus.\n\n \nTamaño de letra en unidades expresdas como una proporción relativa al tamaño de letra definido para el contenido (em). Concretamente, se trata de una fraccción o un múltiplo de escalamiento que se define con referencia al tamaño de letra en uso.\n\n\n{style=“font-size:3em;”}\n\n\nalgo así texto de color y sigo escribiendo.\nPara incluir exponentes se puede recurrir a la modalidad fórmula usando algo así: $m^{2}$ que se verá así: \\(m^{2}\\). Otra opción es recurrir al marcado html. Pondríamos algo así: algo&lt;sup&gt;superíndice&lt;/sup&gt; y se verá así: algosuperíndice. Subíndices, algo semejante, cambiando los códigos necesarios: $m_{2}$ que se verá así: \\(m_{2}\\). En marcado html. Pondríamos algo así: algo&lt;sub&gt;subíndice&lt;/sub&gt; y se verá así: algosubíndice."
  },
  {
    "objectID": "posts/2025-04-04-dar-formato-al-texto/index.html#información-en-pestañas",
    "href": "posts/2025-04-04-dar-formato-al-texto/index.html#información-en-pestañas",
    "title": "Dar formato a mi documeto",
    "section": "Información en “pestañas”",
    "text": "Información en “pestañas”\nPuede resultarte interesante considerar presentar tu información como si se tratara de una libreta con secciones reconocibles por pestañas. Para hacerlo, el bloque (div) se contruye así.\n\n::: {.panel-tabset}\n## Descripción de los datos\nEs realmente un subdocumento, que podrá tener texto, código, gráficas, etc.\n## Estrategia analítica\nMisma cosa. Subdocumento en el que abordas el tema que anuncias en la pestaña.\n:::\n\n\nDescripción de los datosEstrategia analítica\n\n\nEs realmente un subdocumento, que podrá tener texto, código, gráficas, etc.\n\n\nMisma cosa. Subdocumento en el que abordas el tema que anuncias en la pestaña.\n\n\n\nHay muchas posibilidades para dar formato a un documento. Lo que describí aquí son sólo cosas elementales. Otros recursos disponibles son temas, definición de estilos con archivos *.css o *.scc. Más información la podrás encontrar acá. Puedes darte una idea de las posibilidades visitando la galería.\nPor otro lado, te sugiero dosificar el esfuerzo. Nuestro propósito es la comunicación efectiva de contenidos científicos y la documentación reproducible de los procesos de producción de conocimiento nuevo en los que participes. Esto sugiere que hay que procurar mantener al mínimo el uso de variantes estilísticas en tus documentos, aunque hay que recordar también que somos sensibles al valor estético de lo que observamos. Desde luego, ser minimalista no te debe impedir elaborar algunos productos muy cuidados en los que los elementos de diseño tomarán un papel relevante: presentaciones para público general, libros, manuales, infografías, tableros interactivos (dashboards), etc. Siempre, deberás encontrar un equilibrio entre estética y funcionalidad. También recuerda ser ordenado en tus procesos. Cada proyecto un directorio nuevo, adecuadamente documentado y preservado.\nCómo configurar un sitio web en Quarto\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfigura un Blog\nEs básicamente un Website con una landing-page que genera automáticamente una lista del contenido del blog (los documentos contenidos en posts).\n\ndocumento definiendo la landing-page index.qmd en directorio raíz.\nespecificar en el archivo de control un directorio base de contribuciones.\ndocumento de metadatos que especifica como tratar el contenido de contribuciones\n\nEscribir una presentación Revealjs"
  },
  {
    "objectID": "posts/2025-04-04-dar-formato-al-texto/index.html#extensiones-para-quarto",
    "href": "posts/2025-04-04-dar-formato-al-texto/index.html#extensiones-para-quarto",
    "title": "Dar formato a mi documeto",
    "section": "Extensiones para Quarto",
    "text": "Extensiones para Quarto\nQuarto, como R, es una pieza de software que propicia la colaboración abierta en su desarrollo, así que hay creciente núumero de extensiones. Algunas de ellas las encuentras aquí. Para el caso particular de las presentaciones te interesará aprender algunas técnicas avanzadas."
  },
  {
    "objectID": "posts/2025-04-04-dar-formato-al-texto/index.html#cómo-incluir-diagramas-en-mi-blog",
    "href": "posts/2025-04-04-dar-formato-al-texto/index.html#cómo-incluir-diagramas-en-mi-blog",
    "title": "Dar formato a mi documeto",
    "section": "Cómo incluir diagramas en mi blog",
    "text": "Cómo incluir diagramas en mi blog\nPor ejemplo algo muy útil como un diagrama de Gantt. Se puede construir a partir de una especificación de elementos según comandos clave de la aplicación mermaid para la produción de diveros tipos de diagrams basados en Java Script. La documentación e incluso un herramienta de diseño auxiliar se encuentra en la documentación de mermaid.\n \n\n\nmuestra el escript:\nlibrary(DiagrammeR)\n\nm &lt;- mermaid(\n\"\n  gantt\n      dateFormat YYYY-MM-DD\n      title Un diagrama de Gantt\n  \n      section Grupo 1\n         Una tareas      :a1, 2025-03-01, 30d\n         Otra tarea      :after a1, 25d\n      section Grupo 2\n         Tarea en grupo 2 :a2, 2025-10-01, 12d\n         Otra tareaa en 2 :after a2, 24d\n\"\n    \n)\n\n\nm\n\n\n\n\n\n\n \nEste otro ejemplo ilustra como puede hacerse un diagrama de flujo.\n \n\n\nmuestra el escript:\nmermaid(\"\n  graph LR\n    A--&gt;B\n    A--&gt;C\n    C--&gt;E\n    B--&gt;D\n    C--&gt;D\n    D--&gt;F\n    E--&gt;F\n\")\n\n\n\n\n\n\nmuestra el escript:\nmermaid(\"graph LR;A(cuadrado redondeado)--&gt;B[cuadrado];B--&gt;C{Una decisión};\n C--&gt;D[Cuadrado uno];C--&gt;E[Cuadrado dos];\n style A fill:#E5E25F;  style B fill:#87AB51; style C fill:#3C8937;\n style D fill:#23772C;  style E fill:#B6E6E6;\"\n)\n\n\n\n\n\n\nEste es un DAG (grafo acíclico dirigido) que representa un diagrama de influencia con interpretnción causal. En este caso se usa el lenguaje de diagramación [dot](https://en.wikipedia.org/wiki/DOT_(graph_description_language). Aquí puedes ver ejemplos de diagramas producidos con esta herramienta.\n \n\n\nmuestra el escript:\ngrViz(engine = \"dot\", \n  diagram =  \"\n      digraph DAG {\n      \n        # características generales del diagram\n        graph [overlap = true, fontsize = 8]\n\n        # Usa rectángulos para representar los 'nodos'\n        node [overlap = true,\n              shape = box,\n              fontname = Helvetica,\n              color = blue,\n              style = filled,\n              fillcolor = pink]\n        Visita_Asia; Tuberculosis; Fumador;\n        Cancer_pulmonar; Bronquitis; \n        Rayos_X;Disnea\n        \n        node [shape = record,\n              fontname = Helvetica,\n              color = red,\n              style = filled,\n              fillcolor = cyan]\n        t_o_c [label='tuberculosis\\\\no\\\\ncancer\\\\n|{si:|no:}|{{[(?, ?)]}|{[(?, ?)]}}']; \n\n      \n        # patrón de 'influencia'\n        Visita_Asia-&gt;Tuberculosis\n        Tuberculosis-&gt;t_o_c\n        t_o_c-&gt;Rayos_X\n        t_o_c-&gt;Disnea\n        Fumador-&gt;Cancer_pulmonar\n        Fumador-&gt;Bronquitis\n        Cancer_pulmonar-&gt;t_o_c\n        Bronquitis-&gt;Disnea\n      }\n      \"\n  )"
  },
  {
    "objectID": "posts/2025-04-10-storytelling-con-datos/index.html",
    "href": "posts/2025-04-10-storytelling-con-datos/index.html",
    "title": "¿Narrativas con datos?",
    "section": "",
    "text": "Se suele pensar que los datos puros y duros sólo los pueden entender unos pocos genios o, al menos, especialistas. Esta concepción, cierta o no, se relaciona con hechos que estan cambiando nuestras vidas. La empresa IDC, una influyente firma mundial de inteligencia de mercado publicó como un White paper el estudio de David Reinsel et al. (2018) al respecto. En él se sostiene que los volúmenes mundiales de generación de datos están ya alcanzarán los 175 zettabytes (\\(10^{21}\\) bytes), simple magnitud que no se si alguno de nosotros puede imaginar. La velocidad a la cual ha ocurrido este descomunal crecimiento humano del Big Data no sólo en volumen, sino en complejidad impulsa la frenética carrera en la que muchas empresas luchan por mantenerse al día. ¿Cómo intentamos encontrar sentido humano en este oceano de datos? Se ha desarrollado brutalmente la visualización de datos (diagramas, gráficos, infografías) para representar y generar entendimiento entre las toneladas de datos. Desde luego los gráficos simples pueden no bastar. Importa poner en contexto las ideas impulsadas por datos. Ha surgido también el storytelling de datos, que se vislumbra como la nueva generación de comunicación para los negocios. ¿Serán estas apreciaciones igualmente válidas para la ciencia? ¿Deberían la ciencia y la investigación agronómica y ambiental adoptar estos enfoques de análisis y comunicación? Zamith (2021) ha producido un libro en línea que habla sobre esta perspectiva desde un punto de vista del periodismos de datos, y lo explora con ayuda de R, podría ser de tu interé. El mismo autor tiene otras publicaciones en su página de perfil, que también son interesantes.\nTe sugiero considerar seriamente lo que analízan David Reinsel et al. (2018). A lo mejor incluso nos podríamos beneficiar de que lo converses con tus amigos de la escuela y también con los de otros ámbitos. ¿Qué piensas?, ¿qué piensan? ¿qué nos convendrá hacer? Finalmente, te quiero invitar a que consideres las ideas de Knaflic (2017). Ella es una exitosa licenciada en Matemática Aplicada y Maestra en Negocios y Administracióm. Ha establecido una empresa basada en visualización y narrativas de datos. Tiene un espacio en el que ofrece oportunidades para ensayar y pulir tus habilidades comunicativas, a lo mejor nosotros podríamos seguir su ejemplo, quizás te interese asomarte para ver como lo hace.\nSegún Knaflic, para preparar una historia con datos hay que dominar seis habilidades fundamentales:\nLas historias que queremos contar son Grandes Ideas, naturalmente. Pero, ¿Cómo podemos atraer a otros para que se enteren de esa gran cosa? La misma autora, nos dice: despertar el interés hacia una Gran Idea eficazmente, exige reducir al mínimo todo lo que pudiera distraer, hay que buscar llegar a una sóla frase. Quizás es el texto que presentaras en el título de un artículo, en la declaración de objetivos o al hablar con la profe o con alguién que podría financiar el proyecto. Sugiere considerar estos tres pasos para lograr esta síntesis prodigiosa:\nAparentemente esta noción la expresó en 1988 el estratega militar Charles W. Taylor. Le angustiaban las situaciones que podrían, en un futuro próximo, hacer disminuir el apoyo gubernamental al ejército. ¿Te suena familiar la inquietud? Taylor imaginó que la situación se parece a un embudo que se forma en el tiempo. La mayor certeza está en la punta del embudo que ocurre cerca del tiempo presente. Se desarrolla un aumento progresivo de la incertidumbre conforme vislumbramos hacia futuros cada vez más distantes. Me pareció muy familiar la idea, al considerar lo que solemos hacer al preparar un estudio científico. Iniciamos por un análisis de estado del arte, resolvemos así lo que damos por certero o sabido hoy. De ahí nos aventuramos a lo desconocido, tratando de sondear lo posible y proponemos hipótesis de lo que podría ser. ¿Compartes mi sensación?\nEncuentro la idea facinante. ¿Se relacionará esto con la escritura de reportes científicos o técnicos? La mera idea de imaginar narrativas con datos evoca algo de tensión entre la escritura literaria y la austeridad científica. A lo mejor esta otra ilustración despieta tu imaginación (Figura 4). ¿Puedes acomodar aquí: antecedentes, objetivo, métodos, resultados, discusión y conclusiones? ¿Deberías hacerlo o evitarlo? o ¿es enteramente otra cosa?\nCommo afirma Knaflic (2017), hoy, ser experto en procesadores de texto, hojas de cálculo y presentaciones se interpreta como nivel básico, y todo lo que seamos capaces de hacer más avanzado es lo que nos distingue del resto. Pienso que lo que hemos estado buscando en este taller va en dirección de lograr tales ventajas: poder contar historias con datos de manera efectiva, asegurar la trazabilidad desde el diseño mismo del estudio y seguir consistentemente a través de la adquisición de datos, el análisis y el reporte (Center for Open Science, 2025; Möhring et al., 2021; Nosek et al., 2018; The Penn Wharton Credibility Lab, 2025).\nEl tema es parte de las muchas cosas que están ocurriendo en estos tiempos posmodernos y de la posverdad. También están las muchas inconformidades que surgen en nosotros y en nuestro alrededor. Una miradita a lo que piensan algunos miembros de la comunidad inclinada a la convicción de que debemos encontrar formas de contar historias con base en datos es Lydia Hooper. De sus ideas se ha producido una ilustración como la que se muestra en la Figura 5. Me gusta lo que resalta la figura en favor de reubicar los valores humanos en el centro de la historia. Lo encuentro relacionado con el interés de reconstruir o hasta reinventar imaginarios, que es parte del oficio de la ciencia. La comunicació de resultados científicos considerando el contexto subjetivo de lo humano es sin duda un gran desafío (Krackov, 2024)."
  },
  {
    "objectID": "posts/2025-04-10-storytelling-con-datos/index.html#lecturas-sugeridas",
    "href": "posts/2025-04-10-storytelling-con-datos/index.html#lecturas-sugeridas",
    "title": "¿Narrativas con datos?",
    "section": "Lecturas sugeridas",
    "text": "Lecturas sugeridas\n\nCenter for Open Science. (2025). COS - Preregistration. https://www.cos.io/initiatives/prereg\n\n\nDavid Reinsel, Gantz, J., & Rydning, J. (2018). The Digitization of the World from Edge to Core. IDC. https://bit.ly/4kVzcyv\n\n\nKnaflic, C. N. (2017). Storytelling con datos. Visualización de datos para profesionales. Anaya Multimedia. https://www.storytellingwithdata.com/\n\n\nKrackov, A. (2024). Can Community Data Help Heal Public Discourse?, Nightingale. En Nightingale. https://nightingaledvs.com/can-community-data-help-heal-public-discourse/\n\n\nLupton, E. (2019). El diseño como storytelling. Editorial GG. https://editorialgg.com/el-diseno-como-storytelling-libro.html\n\n\nMöhring, N., Schaub, S., & Muller, A. (2021). OSF Registries  Pre-registration plan for: «Scaling-up the adoption of organic farming: a systematic scoping review of policy recommendations». https://osf.io/7k9yr\n\n\nNosek, B. A., Ebersole, C. R., DeHaven, A. C., & Mellor, D. T. (2018). The preregistration revolution. Proceedings of the National Academy of Sciences, 115(11), 2600-2606. https://doi.org/10.1073/pnas.1708274114\n\n\nThe Penn Wharton Credibility Lab. (2025). AsPredicted. The University of Pennsylvania. https://aspredicted.org/\n\n\nZamith, R. (2021). Data-Driven Storytelling. UMass Amherst Libraries. https://books.rodrigozamith.com/data-driven-storytelling/"
  },
  {
    "objectID": "posts/bienvenida/index.html",
    "href": "posts/bienvenida/index.html",
    "title": "Blog de Reproducibilidad Científica",
    "section": "",
    "text": "Este es un espacio para conversar sobre Ciencia Reproducible. La figura ilustra los pilares de la reproducibilidad de acuerdo con lo expresado en este artículo de González-Rayas, et al., 2020"
  },
  {
    "objectID": "posts/2025-04-11-datos-abiertos/index.html#precios-según-el-siap",
    "href": "posts/2025-04-11-datos-abiertos/index.html#precios-según-el-siap",
    "title": "Datos abiertos",
    "section": "Precios según el SIAP",
    "text": "Precios según el SIAP\nENcontré que su forma de reportarlos es un poco complicada en términos informáticos. Lo que hacen es generar en forma dinámica una tabla que incluyen como un iframe, es decir es un visor externo que despliega el reporte producido a petición del usuario.\nPara obtener los datos propiamente hay que hacer la cocnslta mediante estos datos:\n\nurl base: http://www.economia-sniim.gob.mx/nuevo/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas/\ngenerador de la tabla de datos: ResultadosConsultaFechaFrutasYHortalizas.aspx \nfechaInicio: 01/02/2025  fechaFinal: 01/04/2025  ProductoId 426  OrigenId 30  Origen Veracruz  DestinoId 301  Destino Veracruz:%20Central%20de%20Abasto%20de%20Jalapa  PreciosPorId 2  RegistrosPorPagina 500  \n\nhttp://www.economia-sniim.gob.mx/SNIIM-AN/estadisticas/e_fyhAnuarioa.asp?\n\n\nmuestra el escript:\npacman::p_load(rvest, DT, dplyr, stringr)\n\ncat_dest &lt;- read.csv(file = \"sniim-destinos.csv\", quote = \"'\")\ncat_frut &lt;- read.csv(file = \"sniim-frutas-hortalizas.csv\")\ncat_flor &lt;- read.csv(file = \"sniim-flores.csv\")\ncat_gran &lt;- read.csv(file = \"sniim-granos-semillas.csv\")\ncat_acei &lt;- read.csv(file = \"sniim-aceite.csv\")\ncat_insu &lt;- read.csv(file = \"sniim-insumo.csv\")\n\ncat_dest |&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\nmuestra el escript:\ncat_frut |&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\nmuestra el escript:\ncat_flor|&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\nmuestra el escript:\ncat_gran |&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\nmuestra el escript:\ncat_acei |&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\nmuestra el escript:\ncat_insu |&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\n\n\nmuestra el escript:\nurl_limon &lt;- \"http://www.economia-sniim.gob.mx/nuevo/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas/ResultadosConsultaFechaFrutasYHortalizas.aspx?fechaInicio=01/02/2025&fechaFinal=01/04/2025&ProductoId=426&OrigenId=30&Origen=Veracruz&DestinoId=301&Destino=Veracruz:%20Central%20de%20Abasto%20de%20Jalapa&PreciosPorId=2&RegistrosPorPagina=500\"\n\npage &lt;- read_html(url_limon)\n\ntabla_precios&lt;- page %&gt;%\n  html_node(\"table#tblResultados\") |&gt; \n  html_table(header = TRUE) |&gt; \n  slice(-1) %&gt;% \n  rename_with(., ~ str_replace_all(iconv(.x, to='latin1//TRANSLIT'), \"'\", \"\"))\n\n# print result to console\nprint(tabla_precios[])\n\n\n# A tibble: 40 × 6\n   Fecha      Presentación `Precio Mín` `Precio Max` `Precio Frec` Obs. \n   &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;\n 1 04/02/2025 Kilogramo    10.00        15.00        15.00         \"\"   \n 2 05/02/2025 Kilogramo    10.00        15.00        15.00         \"\"   \n 3 06/02/2025 Kilogramo    10.00        15.00        15.00         \"\"   \n 4 07/02/2025 Kilogramo    10.00        15.00        15.00         \"\"   \n 5 10/02/2025 Kilogramo    10.00        15.00        15.00         \"\"   \n 6 11/02/2025 Kilogramo    10.00        15.00        15.00         \"\"   \n 7 12/02/2025 Kilogramo    10.00        15.00        15.00         \"\"   \n 8 13/02/2025 Kilogramo    10.00        15.00        15.00         \"\"   \n 9 14/02/2025 Kilogramo    10.00        15.00        15.00         \"\"   \n10 17/02/2025 Kilogramo    15.00        18.00        18.00         \"\"   \n# ℹ 30 more rows\n\n\n\n\nmuestra el escript:\nurl_1 &lt;- \"http://www.economia-sniim.gob.mx/SNIIM-AN/estadisticas/e_fyhAnuarioa.asp?\"\n\npage &lt;- read_html(url_1)\n\ntable_nodeset &lt;- page %&gt;%\n  html_elements(\"p\") |&gt; \n  html_table()"
  },
  {
    "objectID": "posts/2025-04-11-datos-abiertos/index.html#precios-según-el-sniim",
    "href": "posts/2025-04-11-datos-abiertos/index.html#precios-según-el-sniim",
    "title": "Datos abiertos",
    "section": "Precios según el SNIIM",
    "text": "Precios según el SNIIM\nEncontré que la forma de reportar los datos en la página del SNIIM es un poco complicada en términos informáticos. Lo que hacen es generar en forma dinámica una tabla con la información solicitada, pero en lugar de poner los datos en una tabla directamente, producen un iframe, es decir ofrecen sólo una especie de visor a datos que están en otro lado, aunque al desplegar el reporte producido a petición del usuario, parecería que está todo en un sólo documento que se despliega en el navegador, pero no es realmente así.\nPara obtener los datos y poderlos cargar a una tabla en R, es mejor hacer una cosulta directamente a la base de datos. Para eso necesitamos algunos datos específicos que obtendremos de los siguientes catálogos que, con un poco de maña, se pueden obtener del propio sitio del SNIIM, yo ya lo hice por tí y aquí están. A continuación podrás consultar estos catálogos para que contruyas peticiones a tu gusto.\n \n\n\nmuestra el escript:\npacman::p_load(rvest, DT, dplyr, stringr, ggplot2, scales)\n\ncat_dest &lt;- read.csv(file = \"sniim-destinos.csv\", quote = \"'\")\ncat_frut &lt;- read.csv(file = \"sniim-frutas-hortalizas.csv\")\ncat_flor &lt;- read.csv(file = \"sniim-flores.csv\")\ncat_gran &lt;- read.csv(file = \"sniim-granos-semillas.csv\")\ncat_acei &lt;- read.csv(file = \"sniim-aceite.csv\")\ncat_insu &lt;- read.csv(file = \"sniim-insumo.csv\")\n\ncat_dest |&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\nmuestra el escript:\ncat_frut |&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\nmuestra el escript:\ncat_flor|&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\nmuestra el escript:\ncat_gran |&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\nmuestra el escript:\ncat_acei |&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\nmuestra el escript:\ncat_insu |&gt; \n  datatable(options = list(pageLength = 1))\n\n\n\n\n\n\n\n\nHagamos un ejercicio con los precios del limón sin semilla en Xalapa, entre las fechas 01/feb/2025 y 01/abr/2025. Para hacer esto necesitamos los siguientes datos.\n\nurl base: http://www.economia-sniim.gob.mx/nuevo/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas/\nescript de consulta:ResultadosConsultaFechaFrutasYHortalizas.aspx\ngenerador de la tabla de datos: ResultadosConsultaFechaFrutasYHortalizas.aspx \nfechaInicio: 01/01/2025  fechaFinal: 01/04/2025  ProductoId 426  OrigenId 30  Origen Veracruz  DestinoId 301  Destino Veracruz: Central de Abasto de Jalapa  PreciosPorId 2 (este código se refiere a kg unitario)  RegistrosPorPagina 500  \n\nAhora, semejante a los ejemplos anteriores, tomamos la URL base y, en este caso, la juntamos con la llamada al escript que se encarga de hacer la consulta a la base de datos y le ponemos una iterrogación al final. luego hacemos la consulta que nos interesa, agregando los datos separados por el símbolo &, así:\n\nhttp://www.economia-sniim.gob.mx/nuevo/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas/ResultadosConsultaFechaFrutasYHortalizas.aspx?fechaInicio=01/02/2025&fechaFinal=01/04/2025&ProductoId=426&OrigenId=30&Origen=Veracruz&DestinoId=301&Destino=Veracruz: Central de Abasto de Jalapa&PreciosPorId= 2&RegistrosPorPagina=500\n\nEn general no conviene usar espacios entre palabras en las URL, así que se suelen substituir por el código %20. Si tu consulta llegara a fallar, esta es una cosa que podrías intentar, pero antes checa que todo se vea según tu plan. Por cierto, notarás que cada elemento de la consulta tiene un nombre de parámetro y un valor, separados por el signo “=”. Normalmente esto sugiere que el orden en el que pongas las cosas no importa, salvo la parte que está antes de la interrogación. Aquí hay algo de documentación de este servicos gubernamental.\nListo, hagamos la consulta para averiguar el patrón de precios del limón sin semilla en lo que va de 2025 en Xalapa, Ver.\n \n\n\nmuestra el escript:\nurl_limon &lt;- \"http://www.economia-sniim.gob.mx/nuevo/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas/ResultadosConsultaFechaFrutasYHortalizas.aspx?fechaInicio=01/01/2025&fechaFinal=01/04/2025&ProductoId=426&OrigenId=30&Origen=Veracruz&DestinoId=301&Destino=Veracruz:%20Central%20de%20Abasto%20de%20Jalapa&PreciosPorId=2&RegistrosPorPagina=500\"\n\npage &lt;- read_html(url_limon)\n\ntabla_precios &lt;- page %&gt;% \n  html_node(\"table#tblResultados\") %&gt;%\n  html_table(header = TRUE) %&gt;% \n  slice(-1) %&gt;% \n  mutate(precio_num = as.numeric(`Precio Frec`),\n         feha_d = as.Date(Fecha, format = \"%d/%m/%Y\")) %&gt;% \n  rename_with(., ~ str_replace_all(iconv(.x, to='latin1//TRANSLIT'), \"'\", \"\"))\n\n# print result to console\n\ntabla_precios |&gt;\n  select(Fecha:Obs.) |&gt; \n  datatable()\n\n\n\n\n\n\nmuestra el escript:\ntabla_precios |&gt; \n  ggplot(aes(x = feha_d, y = precio_num)) +\n    geom_point() +\n    geom_smooth(method = 'loess', formula = 'y ~ x', span = 0.3) +\n    labs(title = \"Precio del limón sin semilla\", \n         subtitle = \"Xalapa, Ver. entre 1/ene/2025 y 1/abr/2025\") +\n    xlab(label = \"Fecha\") +\n    ylab(label = \"Precio ($ mn/kg)\") +\n    scale_x_date(labels = date_format(\"%b-%Y\", locale = \"es\"))"
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#hola",
    "href": "posts/2025-05-02-presentacion/index.html#hola",
    "title": "Otra manera de Presentar",
    "section": "",
    "text": "En el manual de Quarto hay información sobre presentaciones"
  },
  {
    "objectID": "posts/2025-04-11-datos-abiertos/postgres-ejemplo.html",
    "href": "posts/2025-04-11-datos-abiertos/postgres-ejemplo.html",
    "title": "Ciencia Abierta",
    "section": "",
    "text": "Ahora Windows incluye la opción de habilitar una versión de linux virtual que convive con el ambiente Windows, la característica se denomina Windows Subsystem Linux (WSL). Hay que habilitarlo desde el panel de control como características de Windows como se ilustra en la Figura 1, o mediante comandos desde una ventana de Powershell (🪟 + X y luego I).\n\n\n\n\n\n\nFigura 1: Activar WSL desde el Panel de Control de Windows\n\n\n\n \nwsl --install\nwsl --version\nwsl --install -d ubuntu\n \nHabrá ahora un ícono con el pingüino de Linux en tu equipo, que es un enlace a una ventana de terminal directamente asociada con WSL. Más adelante será una forma de acceso conveniente, pero por lo pronto puedes seguir con la que ya tienes de Powershell.\n\n\n\nEl pingüino de Linux debe andar por ahí en tu equipo\n\n\n\n\n\nUna vez activado WSL, tendrás, en este ejemplo, un linux Ubuntu en marcha. Ahora puedes instalar PostgreSQL en esa máquina virtual. Lo primero es acceder a linux mediante una consola de sistema. Bastará con que escribas wsl en Powershell. Puede ser la misma ventana que usaste para instalar todo, si todavía la tienes abierta, o usar el nuevo ícono del pingüino. Ahora, escribe las siguientes instrucciones en linux. Básicamente le estas diciendo que entre en modo de superusuario (sudo) y que vaya al servicio general de almacenamiento de aplicaciones (apt-get) y conseguir lo necesario para instalar PostgreSQL en la versión que incluye extensiones y adiciones comunes al PostgreSQL básico.\nsudo apt-get install postgresql postgresql-contrib\nLa instalación inicial de PostgreSQL utiliza como usuario de arranque a postgres. Es necesario darle un password para lograr que PostgreSQL nos de acceso. El siguiente comando lo hace. Te generará una línea en la que te pide ingreses la nueva clave que quieras darle al usuario postgres. Escribiras pero no verás lo que escribes, por seguiridad obviamente. Al terminar aprieta la tecla enter/intro/⏎\nsudo passwd postgres\nAhora, desde la misma terminal, tenemos que arrancar a posgtreSQL como un servico activo en el equipo. Esto lo mantendrá en operación hasta que reinicies la máquina, en cuyo caso deberás reiniciar el servicio. La instrucción para hacer esta operación es la siguiente.\n sudo service postgresql start\nEsta mismalínea te sirve para detener el servico (stop en lugar de start), reiniciarlo (restart) o para averiguar si está activo (status).\nConviene generar un usuario de tu preferencia para interactuar con PostgreSQL, evitando dejar como vulnerabilidad la interacción através del usuario común postgres. Para crear ese nuevo usuario usa el siguiente comando.\nsudo -u postgres psql\n\npsql=# alter user &lt;username&gt; with encrypted password '&lt;password&gt;';\ngrant all privileges on database &lt;dbname&gt; to &lt;username&gt; ; \nPara iniciar tu interacción con PostgreSQL incialmente necesitará entrar a la interfaz del sistema con el siguiente comando. Puede ser que te presente alguna advertencia, pero por lo pronto no le hagas caso.\nsudo -u postgres createuser &lt;username&gt;\nPara seguir con el ejercicio necesitamos crear una base de datos nueva. En este caso usaremos datos de ejemplo que ya se han organizado en bases de datos. Recurriremos al sitio del programa Neon de los Estados Unidos.. Veamos la base de datos de los pasajeros del Titanic en su trágico viaje inaugural. Lo primero es preparar a PostgreSQL para alojarla.\nsudo -u postgres createdb titanic\nAhora vamos por la base de datos. En linux existe para este fin el comando wget. Conviene preparar un directorio para poner estos datos de ejemplo. Un lugar posible podría ser dentro de tu directorio home, (asocido al símbolo ) quizás en db-ejemplos. Hay que usar wget con la opción -P** seguida de la ruta deseada para almacenar el contenido de la URL. Si los directorios involucrados existen, los usa, si no, los crea.\nwget https://raw.githubusercontent.com/neondatabase/postgres-sample-dbs/main/titanic.sql -P ~/db-ejemplos\nEn Windows puedes verificar si el archivo solicitado fue cargado en el lugar que quería desde elnavegador de archivos, busca al final de la lista de directorios. Debería estar el pingüino ahí. lo abres y buscas la carpeta home/&lt;tu usuario&gt;/db-ejemplo en la forma usual. Ahí debería estar el archivo titanica.sql.\nSi ya todo está en orden, ahora hay que cargar los datos en la base de datos titanic. El comando para esto es este.\npsql -d titanic -f ~/db-ejemplos/titanic.sql\nSi por falta de derechos de acceso en tu linux, falla algo de lo anterior, esta es la manera de darle todos los derechos al usuario. No siempre una buena idea desde el punto de vista de la seguridad. Lo primero es entrar a la consola de PostgreSQL como un usuario administrativo, es decir postgres, por ejemplo. Nota el cambio en el encabezado de línea en tu terminal.\nsudo -u postgres psql\nAhora ya estas dentro de PostgreSQL los comandos en su lenguaje, SQL, son los siguientes. Nota también que cada comando es terminado con “;”, si no lo incluyes el interprete de SQL considera que no has terminado de construir la instrucción y por tanto no la procesa.\nalter user &lt;username&gt; with encrypted password '&lt;password&gt;';\ngrant all privileges on database &lt;dbname&gt; to &lt;username&gt; ; \n  Para salir de PostgreSQL, usa el comando \\q)  \nUna vez que todo ha sido configurado podrás tener acceso a PostgreSQL y hacer operaciones de todo tipo. A continuación un ejemplo muy sencillo con la bae de datos de ejemplo “titanic”.\n\npacman::p_load(RPostgres, keyring, flextable, DT)\n\n\ntryCatch({\n  drv &lt;- Postgres()\n  print(\"Connecting to Database…\")\n  connec &lt;- dbConnect(drv, \n                      dbname   = \"titanic\",\n                      host     = Sys.getenv(\"psql_eq_ip\"), \n                      port     = Sys.getenv(\"psql_eq_port\"),\n                      user     = key_list(\"psql-eq\")[1,2],\n                      password = key_get(service = \"psql-eq\", \n                                         username = key_list(\"psql-eq\")[1,2]))\n  \n  print(\"Database Connected!\")\n},\nerror=function(cond) {\n  print(cond)\n  print(\"Unable to connect to Database.\")\n})\n\n[1] \"Connecting to Database…\"\n[1] \"Database Connected!\"\n\ndbGetQuery(connec, \"SELECT name, hometown FROM passenger;\") |&gt; \n  datatable()\n\n\n\n\nhead(df)\n\n                                              \n1 function (x, df1, df2, ncp, log = FALSE)    \n2 {                                           \n3     if (missing(ncp))                       \n4         .Call(C_df, x, df1, df2, log)       \n5     else .Call(C_dnf, x, df1, df2, ncp, log)\n6 }                                           \n\n\n  ¿Había algún mexicano en el Titanic? Por supuesto puedes ver esto en los datos que ya transferimos a una tabla en R arriba, pero para fines didácticos veamos como puedes hacer lo mismo directamente en PostgreSQL con SQL. Usaremos el operador ILIKE que permite buscar patrones de caracteres sin distinguir entre mayúsculas y minúsculas. Cosa que no hace el operado LIKE. Más sobre este operador aquí\n \n\ndbGetQuery(connec, \"SELECT name, hometown FROM passenger\n                               WHERE hometown ILIKE '%mex%';\") |&gt; \n  flextable() |&gt; \n  width(width = c(2,3)) |&gt; \n  set_caption(\"Aquí está la respuesta\")\n\nnamehometownUruchurtu, Don. Manuel EMexico City, MexicoBracken, Mr. James HLake Arthur, New Mexico, US\n\n\n  Al terminar el procesamiento hay que cerrar la conexión, ¡práctica de seguridad estandar!  \n\ndbDisconnect(connec)"
  },
  {
    "objectID": "posts/2025-04-11-datos-abiertos/postgres-ejemplo.html#preparar-wsl-y-postgresql-en-windows",
    "href": "posts/2025-04-11-datos-abiertos/postgres-ejemplo.html#preparar-wsl-y-postgresql-en-windows",
    "title": "Ciencia Abierta",
    "section": "",
    "text": "Ahora Windows incluye la opción de habilitar una versión de linux virtual que convive con el ambiente Windows, la característica que denomina Windows Subsystem Linux (WSL). Hay que habilitarlo desde el panel de control como características de Windows como se ilustra en la ?@fig-wsl, o mediante comandos desde una ventana de Powershell (🪟 + X; y luego I).\nwsl --install\nwsl --version\nwsl --install -d ubuntu\nHabrá un ícono con el pingüino de Linux en tu equipo, que es un enlace a una ventana de terminal directamente asociada con WSL. Más adelante será una forma de acceso conveniente, pero por lo pronto puedes seguir con la que ya tienes de Powershell.\nUna vez activado WSL, tendrás, en este ejemplo, un linux Ubuntu en marcha y para acceder a su consola de sistema bastará con que escribas wslen Powershell, que puede ser la misma que usaste para instalar todo.\nEn una ventana de Powershell escribir\n\n\nsudo apt-get install postgresql postgresql-contrib\nLa instalación inicial de PostgreSQL utiliza como usuario de arranque a postgres. Es necesario darle un password para lograr que PostgreSQL nos de acceso.\n\nsudo -u postgres psql\n\nsudo -u postgres createuser &lt;username&gt;\n\nsudo -u postgres createdb &lt;dbname&gt;\n\n$ sudo -u postgres psql\npsql=# alter user &lt;username&gt; with encrypted password '&lt;password&gt;';\ngrant all privileges on database &lt;dbname&gt; to &lt;username&gt; ; \nPara iniciar tu interacción con PostgreSQL incialmente necesitará entrar a la interfaz del sistema con el siguiente comando.\n\nsudo -u postgres psql\n\nsudo -u postgres createuser &lt;username&gt;\n\nsudo -u postgres createdb &lt;dbname&gt;\n\n$ sudo -u postgres psql\npsql=# alter user &lt;username&gt; with encrypted password '&lt;password&gt;';\ngrant all privileges on database &lt;dbname&gt; to &lt;username&gt; ; \nUna vez que todo ha sido configurado podrás tener acceso a PostgreSQL yhacer operaciones de todo tipo. A continuación un ejemplo muy sencillo con la bae de datos de ejemplo “dbdrental”.\n\npacman::p_load(RPostgres, keyring)\n\n\ntryCatch({\n  drv &lt;- Postgres()\n  print(\"Connecting to Database…\")\n  connec &lt;- dbConnect(drv, \n                      dbname   = \"dvdrental\",\n                      host     = Sys.getenv(\"psql_eq_ip\"), \n                      port     = Sys.getenv(\"psql_eq_port\"),\n                      user     = key_list(\"psql-eq\")[1,2],\n                      password = key_get(service = \"psql-eq\", \n                                         username = key_list(\"psql-eq\")[1,2]))\n  \n  print(\"Database Connected!\")\n},\nerror=function(cond) {\n  print(cond)\n  print(\"Unable to connect to Database.\")\n})\n\n[1] \"Connecting to Database…\"\n[1] \"Database Connected!\"\n\ndf &lt;- dbGetQuery(connec, \"SELECT first_name, last_name FROM actor\")\n\nhead(df)\n\n  first_name    last_name\n1   Penelope      Guiness\n2       Nick     Wahlberg\n3         Ed        Chase\n4   Jennifer        Davis\n5     Johnny Lollobrigida\n6      Bette    Nicholson\n\ndbDisconnect(connec)"
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html",
    "href": "posts/2025-05-02-presentacion/index.html",
    "title": "Otra manera de Presentar",
    "section": "",
    "text": "En el manual de Quarto hay información sobre presentaciones"
  },
  {
    "objectID": "posts/2025-04-11-datos-abiertos/postgres-ejemplo.html#preparar-linux-y-postgresql-en-tu-máquina-windows",
    "href": "posts/2025-04-11-datos-abiertos/postgres-ejemplo.html#preparar-linux-y-postgresql-en-tu-máquina-windows",
    "title": "Ciencia Abierta",
    "section": "",
    "text": "Ahora Windows incluye la opción de habilitar una versión de linux virtual que convive con el ambiente Windows, la característica se denomina Windows Subsystem Linux (WSL). Hay que habilitarlo desde el panel de control como características de Windows como se ilustra en la Figura 1, o mediante comandos desde una ventana de Powershell (🪟 + X y luego I).\n\n\n\n\n\n\nFigura 1: Activar WSL desde el Panel de Control de Windows\n\n\n\n \nwsl --install\nwsl --version\nwsl --install -d ubuntu\n \nHabrá ahora un ícono con el pingüino de Linux en tu equipo, que es un enlace a una ventana de terminal directamente asociada con WSL. Más adelante será una forma de acceso conveniente, pero por lo pronto puedes seguir con la que ya tienes de Powershell.\n\n\n\nEl pingüino de Linux debe andar por ahí en tu equipo\n\n\n\n\n\nUna vez activado WSL, tendrás, en este ejemplo, un linux Ubuntu en marcha. Ahora puedes instalar PostgreSQL en esa máquina virtual. Lo primero es acceder a linux mediante una consola de sistema. Bastará con que escribas wsl en Powershell. Puede ser la misma ventana que usaste para instalar todo, si todavía la tienes abierta, o usar el nuevo ícono del pingüino. Ahora, escribe las siguientes instrucciones en linux. Básicamente le estas diciendo que entre en modo de superusuario (sudo) y que vaya al servicio general de almacenamiento de aplicaciones (apt-get) y conseguir lo necesario para instalar PostgreSQL en la versión que incluye extensiones y adiciones comunes al PostgreSQL básico.\nsudo apt-get install postgresql postgresql-contrib\nLa instalación inicial de PostgreSQL utiliza como usuario de arranque a postgres. Es necesario darle un password para lograr que PostgreSQL nos de acceso. El siguiente comando lo hace. Te generará una línea en la que te pide ingreses la nueva clave que quieras darle al usuario postgres. Escribiras pero no verás lo que escribes, por seguiridad obviamente. Al terminar aprieta la tecla enter/intro/⏎\nsudo passwd postgres\nAhora, desde la misma terminal, tenemos que arrancar a posgtreSQL como un servico activo en el equipo. Esto lo mantendrá en operación hasta que reinicies la máquina, en cuyo caso deberás reiniciar el servicio. La instrucción para hacer esta operación es la siguiente.\n sudo service postgresql start\nEsta mismalínea te sirve para detener el servico (stop en lugar de start), reiniciarlo (restart) o para averiguar si está activo (status).\nConviene generar un usuario de tu preferencia para interactuar con PostgreSQL, evitando dejar como vulnerabilidad la interacción através del usuario común postgres. Para crear ese nuevo usuario usa el siguiente comando.\nsudo -u postgres psql\n\npsql=# alter user &lt;username&gt; with encrypted password '&lt;password&gt;';\ngrant all privileges on database &lt;dbname&gt; to &lt;username&gt; ; \nPara iniciar tu interacción con PostgreSQL incialmente necesitará entrar a la interfaz del sistema con el siguiente comando. Puede ser que te presente alguna advertencia, pero por lo pronto no le hagas caso.\nsudo -u postgres createuser &lt;username&gt;\nPara seguir con el ejercicio necesitamos crear una base de datos nueva. En este caso usaremos datos de ejemplo que ya se han organizado en bases de datos. Recurriremos al sitio del programa Neon de los Estados Unidos.. Veamos la base de datos de los pasajeros del Titanic en su trágico viaje inaugural. Lo primero es preparar a PostgreSQL para alojarla.\nsudo -u postgres createdb titanic\nAhora vamos por la base de datos. En linux existe para este fin el comando wget. Conviene preparar un directorio para poner estos datos de ejemplo. Un lugar posible podría ser dentro de tu directorio home, (asocido al símbolo ) quizás en db-ejemplos. Hay que usar wget con la opción -P** seguida de la ruta deseada para almacenar el contenido de la URL. Si los directorios involucrados existen, los usa, si no, los crea.\nwget https://raw.githubusercontent.com/neondatabase/postgres-sample-dbs/main/titanic.sql -P ~/db-ejemplos\nEn Windows puedes verificar si el archivo solicitado fue cargado en el lugar que quería desde elnavegador de archivos, busca al final de la lista de directorios. Debería estar el pingüino ahí. lo abres y buscas la carpeta home/&lt;tu usuario&gt;/db-ejemplo en la forma usual. Ahí debería estar el archivo titanica.sql.\nSi ya todo está en orden, ahora hay que cargar los datos en la base de datos titanic. El comando para esto es este.\npsql -d titanic -f ~/db-ejemplos/titanic.sql\nSi por falta de derechos de acceso en tu linux, falla algo de lo anterior, esta es la manera de darle todos los derechos al usuario. No siempre una buena idea desde el punto de vista de la seguridad. Lo primero es entrar a la consola de PostgreSQL como un usuario administrativo, es decir postgres, por ejemplo. Nota el cambio en el encabezado de línea en tu terminal.\nsudo -u postgres psql\nAhora ya estas dentro de PostgreSQL los comandos en su lenguaje, SQL, son los siguientes. Nota también que cada comando es terminado con “;”, si no lo incluyes el interprete de SQL considera que no has terminado de construir la instrucción y por tanto no la procesa.\nalter user &lt;username&gt; with encrypted password '&lt;password&gt;';\ngrant all privileges on database &lt;dbname&gt; to &lt;username&gt; ; \n  Para salir de PostgreSQL, usa el comando \\q)  \nUna vez que todo ha sido configurado podrás tener acceso a PostgreSQL y hacer operaciones de todo tipo. A continuación un ejemplo muy sencillo con la bae de datos de ejemplo “titanic”.\n\npacman::p_load(RPostgres, keyring, flextable, DT)\n\n\ntryCatch({\n  drv &lt;- Postgres()\n  print(\"Connecting to Database…\")\n  connec &lt;- dbConnect(drv, \n                      dbname   = \"titanic\",\n                      host     = Sys.getenv(\"psql_eq_ip\"), \n                      port     = Sys.getenv(\"psql_eq_port\"),\n                      user     = key_list(\"psql-eq\")[1,2],\n                      password = key_get(service = \"psql-eq\", \n                                         username = key_list(\"psql-eq\")[1,2]))\n  \n  print(\"Database Connected!\")\n},\nerror=function(cond) {\n  print(cond)\n  print(\"Unable to connect to Database.\")\n})\n\n[1] \"Connecting to Database…\"\n[1] \"Database Connected!\"\n\ndbGetQuery(connec, \"SELECT name, hometown FROM passenger;\") |&gt; \n  datatable()\n\n\n\n\nhead(df)\n\n                                              \n1 function (x, df1, df2, ncp, log = FALSE)    \n2 {                                           \n3     if (missing(ncp))                       \n4         .Call(C_df, x, df1, df2, log)       \n5     else .Call(C_dnf, x, df1, df2, ncp, log)\n6 }                                           \n\n\n  ¿Había algún mexicano en el Titanic? Por supuesto puedes ver esto en los datos que ya transferimos a una tabla en R arriba, pero para fines didácticos veamos como puedes hacer lo mismo directamente en PostgreSQL con SQL. Usaremos el operador ILIKE que permite buscar patrones de caracteres sin distinguir entre mayúsculas y minúsculas. Cosa que no hace el operado LIKE. Más sobre este operador aquí\n \n\ndbGetQuery(connec, \"SELECT name, hometown FROM passenger\n                               WHERE hometown ILIKE '%mex%';\") |&gt; \n  flextable() |&gt; \n  width(width = c(2,3)) |&gt; \n  set_caption(\"Aquí está la respuesta\")\n\nnamehometownUruchurtu, Don. Manuel EMexico City, MexicoBracken, Mr. James HLake Arthur, New Mexico, US\n\n\n  Al terminar el procesamiento hay que cerrar la conexión, ¡práctica de seguridad estandar!  \n\ndbDisconnect(connec)"
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#esta-es-la-segunda-diapositiva",
    "href": "posts/2025-05-02-presentacion/index.html#esta-es-la-segunda-diapositiva",
    "title": "Otra manera de Presentar",
    "section": "Esta es la segunda Diapositiva",
    "text": "Esta es la segunda Diapositiva\n\nContenido 1\nContenido 2"
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#una-gráfica-con-ggplot",
    "href": "posts/2025-05-02-presentacion/index.html#una-gráfica-con-ggplot",
    "title": "Otra manera de Presentar",
    "section": "¿Una gráfica con ggplot?",
    "text": "¿Una gráfica con ggplot?"
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#diapo-con-un-bonito-mapa",
    "href": "posts/2025-05-02-presentacion/index.html#diapo-con-un-bonito-mapa",
    "title": "Otra manera de Presentar",
    "section": "Diapo con un bonito mapa",
    "text": "Diapo con un bonito mapa"
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#para-personalizar-la-title-slide-puedes",
    "href": "posts/2025-05-02-presentacion/index.html#para-personalizar-la-title-slide-puedes",
    "title": "Otra manera de Presentar",
    "section": "Para personalizar la Title Slide puedes",
    "text": "Para personalizar la Title Slide puedes\nEn orden de complejidad:\n\nEvitar la portada automática. No pongas ni título ni autor al encabezado YAML de tu documento.\nUsar title-slide-attributes.\n\n\ntitle-slide-attributes: \n  data-background-image: /ruta/a/imágen_para_portada.png   \n  data-background-size: contain   \n  data-background-opacity: \"0.5\"\n\nSubstituir todo con template-partials que permite usar una plantilla html a tu gusto."
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#section",
    "href": "posts/2025-05-02-presentacion/index.html#section",
    "title": "Otra manera de Presentar",
    "section": "",
    "text": "texto 10, 0, 0 texto 10, 0, 50% texto 10, 50%, 0 texto 10, 100%, 100%\n\n\n\n\n\n\n\n\n\n\n\n\nJaguar\n\n\nMiguel Equihua\n\n\n6-agosto-2024"
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#cómo-hacerlo",
    "href": "posts/2025-05-02-presentacion/index.html#cómo-hacerlo",
    "title": "Otra manera de Presentar",
    "section": "Cómo hacerlo",
    "text": "Cómo hacerlo\n\nEn la pestaña de consola ejecuta el siguiente comando\n\nquarto add quarto-ext/pointer\n\nEsto creará un directorio _extensions en la raíz de tu proyecto,\nDentro de _extensions está lo necesario para usar los plugins que instales.\nUn juego completo de diapos con un tema"
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#configuración",
    "href": "posts/2025-05-02-presentacion/index.html#configuración",
    "title": "Otra manera de Presentar",
    "section": "Configuración",
    "text": "Configuración\n\nAgrega esto en el encabezado de tu presentación\n\ntitle: Mi presentación \n  format: \n    revealjs: default\n      pointer: pointerSize: 18       \n      color: #32cd32'       \n\nrevealjs-plugins:\n  - pointer`"
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#listo-como-lo-usas",
    "href": "posts/2025-05-02-presentacion/index.html#listo-como-lo-usas",
    "title": "Otra manera de Presentar",
    "section": "!Listo! ¿como lo usas?",
    "text": "!Listo! ¿como lo usas?\n\nFuente: Imagen de edmondlafoto en Pixabay\n\n\n\n\n\n\n\n\nahora podrás prender y apagar el apuntador con la tecla q\n\n\n\n\n\n\n\n\n\n\ninicio"
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#particles",
    "href": "posts/2025-05-02-presentacion/index.html#particles",
    "title": "Otra manera de Presentar",
    "section": "Particles",
    "text": "Particles\nThis doc showcases how to use particle.js to get a nice header in your quarto document.\nlet’s dive in."
  },
  {
    "objectID": "posts/2025-05-02-presentacion/index.html#para-empezar",
    "href": "posts/2025-05-02-presentacion/index.html#para-empezar",
    "title": "Otra manera de Presentar",
    "section": "Para empezar",
    "text": "Para empezar\nEn el manual de Quarto hay información sobre presentaciones"
  },
  {
    "objectID": "posts/2025-05-02-nuestros-blogs/index.html",
    "href": "posts/2025-05-02-nuestros-blogs/index.html",
    "title": "Nuestros Blogs",
    "section": "",
    "text": "Haremos una página con una galería de muestra de los blogs que estamos construyendo. Por favor comparte tus datos para poderlo hacer. Actualmente tenemos estos Blogs registrados.\n\n\nmuestra el escript:\npacman::p_load(surveydown, flextable, dplyr, stringr)\n\n\ndb &lt;- sd_db_connect(env_file = \".env\", \n                    ignore = FALSE,\n                    gssencmode = \"prefer\")\n\n\n✔ Successfully connected to the database.\n\n\nmuestra el escript:\ndata &lt;- sd_get_data(db = db)\n\ndata |&gt; \n  mutate(blog = str_extract(url_blog, \"(?&lt;=//)(.*)(?=\\\\.netlify\\\\.app)\")) |&gt; \n  filter(nombre != \"\") |&gt;     \n  arrange(nombre) |&gt; \n  select(nombre, url_blog, blog) |&gt; \n  flextable() |&gt; \n  set_header_labels(nombre = \"Nombre\", url_blog = \"URL\", blog = \"Blog\") |&gt; \n  compose(j = 2, value = as_paragraph(hyperlink_text(x = blog, url = url_blog))) |&gt; \n  flextable::delete_columns(j = 3) |&gt; \n  width(j=1:2, width = c(2.5, 4))\n\n\nNombreURLAdrian Canova Herrandizecoeficiencia-en-cafeAndrés De la Rosa Portillaherrameintas-sigDenisse Alejandra Diaz Romocientifi-ktJuan José Hernández ViverosJuan José Hernández ViverosNohemy Cardona ClaroseemmsPitabosquesvictoria carolinaquercus-misteriosos"
  },
  {
    "objectID": "posts/2025-05-02-nuestros-blogs/index.html#blogs-de-participantes",
    "href": "posts/2025-05-02-nuestros-blogs/index.html#blogs-de-participantes",
    "title": "Nuestros Blogs",
    "section": "",
    "text": "Haremos una página con una galería de muestra de los blogs que estamos construyendo. Por favor comparte tus datos para poderlo hacer. Actualmente tenemos estos Blogs registrados.\n\n\nmuestra el escript:\npacman::p_load(surveydown, flextable, dplyr, stringr)\n\n\ndb &lt;- sd_db_connect(env_file = \".env\", \n                    ignore = FALSE,\n                    gssencmode = \"prefer\")\n\n\n✔ Successfully connected to the database.\n\n\nmuestra el escript:\ndata &lt;- sd_get_data(db = db)\n\ndata |&gt; \n  mutate(blog = str_extract(url_blog, \"(?&lt;=//)(.*)(?=\\\\.netlify\\\\.app)\")) |&gt; \n  filter(nombre != \"\") |&gt;     \n  arrange(nombre) |&gt; \n  select(nombre, url_blog, blog) |&gt; \n  flextable() |&gt; \n  set_header_labels(nombre = \"Nombre\", url_blog = \"URL\", blog = \"Blog\") |&gt; \n  compose(j = 2, value = as_paragraph(hyperlink_text(x = blog, url = url_blog))) |&gt; \n  flextable::delete_columns(j = 3) |&gt; \n  width(j=1:2, width = c(2.5, 4))\n\n\nNombreURLAdrian Canova Herrandizecoeficiencia-en-cafeAndrés De la Rosa Portillaherrameintas-sigDenisse Alejandra Diaz Romocientifi-ktJuan José Hernández ViverosJuan José Hernández ViverosNohemy Cardona ClaroseemmsPitabosquesvictoria carolinaquercus-misteriosos"
  },
  {
    "objectID": "posts/2025-05-02-nuestros-blogs/index.html#gracias",
    "href": "posts/2025-05-02-nuestros-blogs/index.html#gracias",
    "title": "¿Qúe puedo incluir en mis documentos?",
    "section": "Gracias",
    "text": "Gracias\n\n\nmuestra el escript:\n#|include: false\n\nsd_close()\n\n\n\nExit Survey"
  }
]